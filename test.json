{
	"url": "https://news.ycombinator.com/item?id=40973339",
	"raw_html": "<html lang=\"en\" op=\"item\"><head><meta name=\"referrer\" content=\"origin\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css?8yh3lTXcP3rMZEYvdlNS\">\n        <link rel=\"icon\" href=\"y18.svg\">\n    <link rel=\"canonical\" href=\"https://news.ycombinator.com/item?id=40973339\">            <title>Exo: Run your own AI cluster at home with everyday devices | Hacker News</title></head><body><center><table id=\"hnmain\" border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"85%\" bgcolor=\"#f6f6ef\">\n        <tbody><tr><td bgcolor=\"#ff6600\"><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\" style=\"padding:2px\"><tbody><tr><td style=\"width:18px;padding-right:4px\"><a href=\"https://news.ycombinator.com\"><img src=\"y18.svg\" width=\"18\" height=\"18\" style=\"border:1px white solid; display:block\"></a></td>\n                  <td style=\"line-height:12pt; height:10px;\"><span class=\"pagetop\"><b class=\"hnname\"><a href=\"news\">Hacker News</a></b>\n                            <a href=\"newest\">new</a> | <a href=\"front\">past</a> | <a href=\"newcomments\">comments</a> | <a href=\"ask\">ask</a> | <a href=\"show\">show</a> | <a href=\"jobs\">jobs</a> | <a href=\"submit\" rel=\"nofollow\">submit</a>            </span></td><td style=\"text-align:right;padding-right:4px;\"><span class=\"pagetop\">\n                              <a href=\"login?goto=item%3Fid%3D40973339\">login</a>\n                          </span></td>\n              </tr></tbody></table></td></tr>\n<tr id=\"pagespace\" title=\"Exo: Run your own AI cluster at home with everyday devices\" style=\"height:10px\"></tr><tr><td><table class=\"fatitem\" border=\"0\">\n        <tbody><tr class=\"athing\" id=\"40973339\">\n      <td align=\"right\" valign=\"top\" class=\"title\"><span class=\"rank\"></span></td>      <td valign=\"top\" class=\"votelinks\"><center><a id=\"up_40973339\" href=\"vote?id=40973339&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center></td><td class=\"title\"><span class=\"titleline\"><a href=\"https://github.com/exo-explore/exo\">Exo: Run your own AI cluster at home with everyday devices</a><span class=\"sitebit comhead\"> (<a href=\"from?site=github.com/exo-explore\"><span class=\"sitestr\">github.com/exo-explore</span></a>)</span></span></td></tr><tr><td colspan=\"2\"></td><td class=\"subtext\"><span class=\"subline\">\n          <span class=\"score\" id=\"score_40973339\">408 points</span> by <a href=\"user?id=simonpure\" class=\"hnuser\">simonpure</a> <span class=\"age\" title=\"2024-07-16T02:55:11\"><a href=\"item?id=40973339\">1 day ago</a></span> <span id=\"unv_40973339\"></span> | <a href=\"hide?id=40973339&amp;goto=item%3Fid%3D40973339\">hide</a> | <a href=\"https://hn.algolia.com/?query=Exo%3A%20Run%20your%20own%20AI%20cluster%20at%20home%20with%20everyday%20devices&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0\" class=\"hnpast\">past</a> | <a href=\"fave?id=40973339&amp;auth=f19dcc230ba19013cbbe18d142953fdafa3b6dcf\">favorite</a> | <a href=\"item?id=40973339\">141&nbsp;comments</a>        </span>\n              </td></tr>\n            <tr><td style=\"height:10px\"></td></tr><tr><td colspan=\"2\"></td><td><form action=\"comment\" method=\"post\"><input type=\"hidden\" name=\"parent\" value=\"40973339\"><input type=\"hidden\" name=\"goto\" value=\"item?id=40973339\"><input type=\"hidden\" name=\"hmac\" value=\"e3c6e7c8cf5e115ae285bc3dce1e362087b3f0e8\"><textarea name=\"text\" rows=\"8\" cols=\"80\" wrap=\"virtual\"></textarea><br><br>\n<input type=\"submit\" value=\"add comment\"></form></td></tr>  </tbody></table><br><br><table border=\"0\" class=\"comment-tree\">\n            <tbody><tr class=\"athing comtr\" id=\"40975469\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975469\" href=\"vote?id=40975469&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=ajnin\" class=\"hnuser\">ajnin</a> <span class=\"age\" title=\"2024-07-16T11:19:35\"><a href=\"item?id=40975469\">1 day ago</a></span> <span id=\"unv_40975469\"></span>          <span class=\"navs\">\n             | <a href=\"#40977799\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975469\" n=\"6\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">It requires mlx but it is an Apple silicon-only library as far as I can tell. How is it supposed to be (I quote) \"iPhone, iPad, Android, Mac, Linux, pretty much any device\" ? Has it been tested on anything else than the author's MacBook ?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975469&amp;goto=item%3Fid%3D40973339%2340975469\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40981110\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40981110\" href=\"vote?id=40981110&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T22:59:03\"><a href=\"item?id=40981110\">18 hours ago</a></span> <span id=\"unv_40981110\"></span>          <span class=\"navs\">\n             | <a href=\"#40975469\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976660\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40981110\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Repo maintainer here. It supports any device tinygrad does, which is a lot. We didn’t expect it to blow up so soon - the repo is still experimental. Internally we’ve mostly been testing on MacBooks and Mac Minis, and that’s where dev is happening. The swift implementation is outdated and currently broken, since Python has been changing so fast (over 20 commits in the last day). On my ToDo is CI/CD pipeline with integration tests for different device and network configurations, so we don’t randomly break stuff for certain devices.<p>We’re moving fast to get it stable and usable. The goal is for this to be as simple as running Dropbox. Bear with us :)</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40981110&amp;goto=item%3Fid%3D40973339%2340981110\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40976660\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976660\" href=\"vote?id=40976660&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=orsorna\" class=\"hnuser\">orsorna</a> <span class=\"age\" title=\"2024-07-16T13:56:25\"><a href=\"item?id=40976660\">1 day ago</a></span> <span id=\"unv_40976660\"></span>          <span class=\"navs\">\n             | <a href=\"#40975469\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40981110\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977818\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976660\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">One of the maintainers has a video demo on his twitter claiming iOS, android and Linux. Some of the code is not released and I wish they were advertising that properly.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976660&amp;goto=item%3Fid%3D40973339%2340976660\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40984200\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40984200\" href=\"vote?id=40984200&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tama_sala\" class=\"hnuser\">tama_sala</a> <span class=\"age\" title=\"2024-07-17T10:05:35\"><a href=\"item?id=40984200\">7 hours ago</a></span> <span id=\"unv_40984200\"></span>          <span class=\"navs\">\n             | <a href=\"#40975469\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976660\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977818\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40984200\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The library already has tinygrad support it seems, so it's not limited to Apple &amp; MLX</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40984200&amp;goto=item%3Fid%3D40973339%2340984200\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40987078\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40987078\" href=\"vote?id=40987078&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=orsorna\" class=\"hnuser\">orsorna</a> <span class=\"age\" title=\"2024-07-17T15:41:07\"><a href=\"item?id=40987078\">1 hour ago</a></span> <span id=\"unv_40987078\"></span>          <span class=\"navs\">\n             | <a href=\"#40975469\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40984200\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977818\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40987078\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">That is true. However (as of two days ago, it may have rapidly changed since then) the python program did not differentiate based on your architecture and would try to import mlx regardless if it's installable on your system or not, causing import errors.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40987078&amp;goto=item%3Fid%3D40973339%2340987078\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40977818\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977818\" href=\"vote?id=40977818&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=lopuhin\" class=\"hnuser\">lopuhin</a> <span class=\"age\" title=\"2024-07-16T16:07:56\"><a href=\"item?id=40977818\">1 day ago</a></span> <span id=\"unv_40977818\"></span>          <span class=\"navs\">\n             | <a href=\"#40975469\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976660\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977799\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977818\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The README says they plan to add llama.cpp support which should cover a lot of targets, also they have tinygrad already integrated I think.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977818&amp;goto=item%3Fid%3D40973339%2340977818\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40977799\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977799\" href=\"vote?id=40977799&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=dcreater\" class=\"hnuser\">dcreater</a> <span class=\"age\" title=\"2024-07-16T16:05:44\"><a href=\"item?id=40977799\">1 day ago</a></span> <span id=\"unv_40977799\"></span>          <span class=\"navs\">\n             | <a href=\"#40975469\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977799\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This is a great ideal and user friendly as well. Has the potential of converting multiple old devices overnight from being useless. However, I wish they had provided some results on tok/s, latency with some example setups.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977799&amp;goto=item%3Fid%3D40973339%2340977799\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977865\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977865\" href=\"vote?id=40977865&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T16:12:45\"><a href=\"item?id=40977865\">1 day ago</a></span> <span id=\"unv_40977865\"></span>          <span class=\"navs\">\n             | <a href=\"#40977799\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977865\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">We didn't expect this to blow up so quickly. A lot of work needs to be done on getting different setups working. I have made an issue here: <a href=\"https://github.com/exo-explore/exo/issues/11\">https://github.com/exo-explore/exo/issues/11</a></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977865&amp;goto=item%3Fid%3D40973339%2340977865\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980767\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980767\" href=\"vote?id=40980767&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=DiogoSnows\" class=\"hnuser\">DiogoSnows</a> <span class=\"age\" title=\"2024-07-16T22:04:42\"><a href=\"item?id=40980767\">19 hours ago</a></span> <span id=\"unv_40980767\"></span>          <span class=\"navs\">\n             | <a href=\"#40977799\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40977865\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980767\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This is great work! I will keep an eye (and maybe even try to contribute).  \nLooking back at the beginning of Google, I think their use of hardware and hardware agnostic platform likely contributed to support growth at lower cost. We need more of that in the AI era</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980767&amp;goto=item%3Fid%3D40973339%2340980767\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980987\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980987\" href=\"vote?id=40980987&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T22:40:19\"><a href=\"item?id=40980987\">18 hours ago</a></span> <span id=\"unv_40980987\"></span>          <span class=\"navs\">\n             | <a href=\"#40977799\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40980767\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980987\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Thank you for the support! I agree on the cost point, and personally I don’t want to live in a world where all AI runs on H100s in a giant datacenter controlled by one company.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980987&amp;goto=item%3Fid%3D40973339%2340980987\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                              <tr class=\"athing comtr\" id=\"40974169\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974169\" href=\"vote?id=40974169&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=mg\" class=\"hnuser\">mg</a> <span class=\"age\" title=\"2024-07-16T06:55:35\"><a href=\"item?id=40974169\">1 day ago</a></span> <span id=\"unv_40974169\"></span>          <span class=\"navs\">\n             | <a href=\"#40977799\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974169\" n=\"13\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\"><p></p><pre><code>    This enables you to run larger models\n    than you would be able to on any single\n    device.\n</code></pre>\nNo further explanation on how this is supposed to work?<p>If some layers of the neural network are on deviceA and some layers are on deviceB, wouldn't that mean that for every token generated, all output data from the last layer on deviceA have to be transferred to deviceB?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974169&amp;goto=item%3Fid%3D40973339%2340974169\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974320\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974320\" href=\"vote?id=40974320&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=mikewarot\" class=\"hnuser\">mikewarot</a> <span class=\"age\" title=\"2024-07-16T07:27:40\"><a href=\"item?id=40974320\">1 day ago</a></span> <span id=\"unv_40974320\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974190\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974320\" n=\"7\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Yes, so you would have a vector about 8k values long to be transferred on each token generated.<p>You could do that easily with any modern network.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974320&amp;goto=item%3Fid%3D40973339%2340974320\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974366\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974366\" href=\"vote?id=40974366&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=mg\" class=\"hnuser\">mg</a> <span class=\"age\" title=\"2024-07-16T07:40:15\"><a href=\"item?id=40974366\">1 day ago</a></span> <span id=\"unv_40974366\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974320\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974190\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974366\" n=\"6\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">That's exciting. So we could build a SETI@home style network of even the largest models.<p>I wonder if training could be done in this way too.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974366&amp;goto=item%3Fid%3D40973339%2340974366\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974403\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974403\" href=\"vote?id=40974403&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T07:48:53\"><a href=\"item?id=40974403\">1 day ago</a></span> <span id=\"unv_40974403\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974366\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974190\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974403\" n=\"5\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Repo author here. That's correct. The embeddings for Llama-3-8B are around 8KB-10KB. For Llama-3-70B they're around 32KB. These are small enough to send around between devices on a local network. For a SETI@home style network, latency will kill you if you go over the internet. That's why we're starting with local networks.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974403&amp;goto=item%3Fid%3D40973339%2340974403\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40975291\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975291\" href=\"vote?id=40975291&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=juvo\" class=\"hnuser\">juvo</a> <span class=\"age\" title=\"2024-07-16T10:49:31\"><a href=\"item?id=40975291\">1 day ago</a></span> <span id=\"unv_40975291\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974403\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980804\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975291\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">how does it compare to <a href=\"https://github.com/bigscience-workshop/petals\">https://github.com/bigscience-workshop/petals</a> ?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975291&amp;goto=item%3Fid%3D40973339%2340975291\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40980804\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980804\" href=\"vote?id=40980804&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=DiogoSnows\" class=\"hnuser\">DiogoSnows</a> <span class=\"age\" title=\"2024-07-16T22:09:18\"><a href=\"item?id=40980804\">19 hours ago</a></span> <span id=\"unv_40980804\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974403\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975291\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974793\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980804\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">For generating synthetic data you could have a SETI@Home setup if you consider each home as a node that generates some amount of data.\nI mean, such a setup can be built with Exo, I wouldn’t suggest including it as part of Exo.<p>Out of curiosity, would you ever support training or at least fine-tuning?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980804&amp;goto=item%3Fid%3D40973339%2340980804\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40974793\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974793\" href=\"vote?id=40974793&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=mg\" class=\"hnuser\">mg</a> <span class=\"age\" title=\"2024-07-16T09:12:35\"><a href=\"item?id=40974793\">1 day ago</a></span> <span id=\"unv_40974793\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974403\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980804\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974190\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974793\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Ah yes. At first, I thought that since it is all one-way forward-only communication, latency would only affect the time to the first token.<p>But I guess the final output needs to be sent back to the first node before it can continue. So if there are 50 nodes with a latency of 40ms each, each token would take 2s to process.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974793&amp;goto=item%3Fid%3D40973339%2340974793\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974826\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"5\"><img src=\"s.gif\" height=\"1\" width=\"200\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974826\" href=\"vote?id=40974826&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T09:19:47\"><a href=\"item?id=40974826\">1 day ago</a></span> <span id=\"unv_40974826\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974793\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974190\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974826\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Yeah, unfortunately the autoregressive nature of these models slows it down significantly with added device&lt;-&gt;device latency. However, you can still max out on throughput with pipeline parallelism, where you overlap execution. See: <a href=\"https://pytorch.org/docs/stable/pipeline.html\" rel=\"nofollow\">https://pytorch.org/docs/stable/pipeline.html</a></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974826&amp;goto=item%3Fid%3D40973339%2340974826\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                                    <tr class=\"athing comtr\" id=\"40974190\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974190\" href=\"vote?id=40974190&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=steeve\" class=\"hnuser\">steeve</a> <span class=\"age\" title=\"2024-07-16T07:00:41\"><a href=\"item?id=40974190\">1 day ago</a></span> <span id=\"unv_40974190\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974320\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974190\" n=\"5\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Yes, that’s how it works (pipeline parallelism)</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974190&amp;goto=item%3Fid%3D40973339%2340974190\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974203\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974203\" href=\"vote?id=40974203&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=mg\" class=\"hnuser\">mg</a> <span class=\"age\" title=\"2024-07-16T07:03:12\"><a href=\"item?id=40974203\">1 day ago</a></span> <span id=\"unv_40974203\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974190\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974203\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c5a\">Interesting. Let's do the math ...<p>Let's say the model has 50B parameters and 50 layers. That would mean about one billion values have to travel through the wifi for every generated token?</p><p>I wonder how much data that is in bytes and how long it takes to transfer them.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974203&amp;goto=item%3Fid%3D40973339%2340974203\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974324\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974324\" href=\"vote?id=40974324&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=blackbear_\" class=\"hnuser\">blackbear_</a> <span class=\"age\" title=\"2024-07-16T07:28:35\"><a href=\"item?id=40974324\">1 day ago</a></span> <span id=\"unv_40974324\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974203\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974324\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">It's not the parameters that are sent, it's the layer outputs. That makes for a few thousands floats per token</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974324&amp;goto=item%3Fid%3D40973339%2340974324\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974355\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974355\" href=\"vote?id=40974355&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=mg\" class=\"hnuser\">mg</a> <span class=\"age\" title=\"2024-07-16T07:37:52\"><a href=\"item?id=40974355\">1 day ago</a></span> <span id=\"unv_40974355\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974324\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974355\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Woops! I would have thought the number of neurons roughly equals the number of parameters, but you are right. The number of parameters is much higher.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974355&amp;goto=item%3Fid%3D40973339%2340974355\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978645\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"5\"><img src=\"s.gif\" height=\"1\" width=\"200\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978645\" href=\"vote?id=40978645&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tama_sala\" class=\"hnuser\">tama_sala</a> <span class=\"age\" title=\"2024-07-16T17:46:24\"><a href=\"item?id=40978645\">23 hours ago</a></span> <span id=\"unv_40978645\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974355\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978645\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The embedding size is only 8k so while the parameters are 70B. So it's a huge difference</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978645&amp;goto=item%3Fid%3D40973339%2340978645\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                                          <tr class=\"athing comtr\" id=\"40975767\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975767\" href=\"vote?id=40975767&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=pyinstallwoes\" class=\"hnuser\">pyinstallwoes</a> <span class=\"age\" title=\"2024-07-16T12:07:35\"><a href=\"item?id=40975767\">1 day ago</a></span> <span id=\"unv_40975767\"></span>          <span class=\"navs\">\n             | <a href=\"#40974169\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975767\" n=\"11\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Swarm compute should be the norm for all compute - so much unused cpu across all the devices we collectively own.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975767&amp;goto=item%3Fid%3D40973339%2340975767\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976968\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976968\" href=\"vote?id=40976968&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=phito\" class=\"hnuser\">phito</a> <span class=\"age\" title=\"2024-07-16T14:29:36\"><a href=\"item?id=40976968\">1 day ago</a></span> <span id=\"unv_40976968\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975929\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976968\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I'd rather my CPU to be idle and not consome much power</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976968&amp;goto=item%3Fid%3D40973339%2340976968\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40979229\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979229\" href=\"vote?id=40979229&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=imp0cat\" class=\"hnuser\">imp0cat</a> <span class=\"age\" title=\"2024-07-16T18:56:50\"><a href=\"item?id=40979229\">22 hours ago</a></span> <span id=\"unv_40979229\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976968\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975929\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979229\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">It depends. There is a lot of devices with quite capable cpus that are mostly doing nothing.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979229&amp;goto=item%3Fid%3D40973339%2340979229\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40981055\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40981055\" href=\"vote?id=40981055&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=bastawhiz\" class=\"hnuser\">bastawhiz</a> <span class=\"age\" title=\"2024-07-16T22:50:19\"><a href=\"item?id=40981055\">18 hours ago</a></span> <span id=\"unv_40981055\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40979229\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975929\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40981055\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I also prefer my phone to not be hot and constantly plugged in. Or for my ML workload to suddenly get slow because my partner drove the car out of range of the WiFi. Or to miss notifications because my watch's CPU was saturated.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40981055&amp;goto=item%3Fid%3D40973339%2340981055\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40975929\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975929\" href=\"vote?id=40975929&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=KronisLV\" class=\"hnuser\">KronisLV</a> <span class=\"age\" title=\"2024-07-16T12:32:50\"><a href=\"item?id=40975929\">1 day ago</a></span> <span id=\"unv_40975929\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976968\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976338\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975929\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This might not work for use cases where you need low latency, but for longer winded processing it would be amazing if possible.<p>For example, if I have a few servers, laptop (connected to power) as well as a desktop PC and they’re all connected to a fast local network, it’d be great to distribute the task of rendering a video or working with archive files across all of them.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975929&amp;goto=item%3Fid%3D40973339%2340975929\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976200\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976200\" href=\"vote?id=40976200&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=greggsy\" class=\"hnuser\">greggsy</a> <span class=\"age\" title=\"2024-07-16T13:07:47\"><a href=\"item?id=40976200\">1 day ago</a></span> <span id=\"unv_40976200\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975929\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976338\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976200\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Those are two precise examples that benefit from single core compute power, and are wholly unsuited to distributed computing…</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976200&amp;goto=item%3Fid%3D40973339%2340976200\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976988\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976988\" href=\"vote?id=40976988&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=KronisLV\" class=\"hnuser\">KronisLV</a> <span class=\"age\" title=\"2024-07-16T14:31:47\"><a href=\"item?id=40976988\">1 day ago</a></span> <span id=\"unv_40976988\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976200\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976338\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976988\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Distributed rendering farms have existed for a while.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976988&amp;goto=item%3Fid%3D40973339%2340976988\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40985816\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40985816\" href=\"vote?id=40985816&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=greggsy\" class=\"hnuser\">greggsy</a> <span class=\"age\" title=\"2024-07-17T13:39:08\"><a href=\"item?id=40985816\">3 hours ago</a></span> <span id=\"unv_40985816\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976988\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976338\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40985816\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">They render a single frame though. Admittedly, so does video rendering.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40985816&amp;goto=item%3Fid%3D40973339%2340985816\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                              <tr class=\"athing comtr\" id=\"40976338\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976338\" href=\"vote?id=40976338&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=_factor\" class=\"hnuser\">_factor</a> <span class=\"age\" title=\"2024-07-16T13:21:38\"><a href=\"item?id=40976338\">1 day ago</a></span> <span id=\"unv_40976338\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975929\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976338\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This exists: <a href=\"https://aihorde.net/\" rel=\"nofollow\">https://aihorde.net/</a><p>I haven’t tried it, and not the norm, but I agree it should be more common.  We have a global supercomputer with higher latency, but still a supercomputer.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976338&amp;goto=item%3Fid%3D40973339%2340976338\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976753\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976753\" href=\"vote?id=40976753&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=dchuk\" class=\"hnuser\">dchuk</a> <span class=\"age\" title=\"2024-07-16T14:05:51\"><a href=\"item?id=40976753\">1 day ago</a></span> <span id=\"unv_40976753\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976338\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976753\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I might just still be too tired from just waking up, but I can’t for the life of me find any details on that site about what models are actually being served by the horde?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976753&amp;goto=item%3Fid%3D40973339%2340976753\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977160\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977160\" href=\"vote?id=40977160&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=burkaman\" class=\"hnuser\">burkaman</a> <span class=\"age\" title=\"2024-07-16T14:50:55\"><a href=\"item?id=40977160\">1 day ago</a></span> <span id=\"unv_40977160\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976753\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977160\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Go to <a href=\"https://aihorde.net/api/\" rel=\"nofollow\">https://aihorde.net/api/</a>, scroll down to /v2/status/models, and click Try it out and then Execute. It's an enormous list and I think it can be dynamically updated, so that's probably why it isn't listed on the website.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977160&amp;goto=item%3Fid%3D40973339%2340977160\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                              <tr class=\"athing comtr\" id=\"40973770\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973770\" href=\"vote?id=40973770&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=hagope\" class=\"hnuser\">hagope</a> <span class=\"age\" title=\"2024-07-16T05:04:59\"><a href=\"item?id=40973770\">1 day ago</a></span> <span id=\"unv_40973770\"></span>          <span class=\"navs\">\n             | <a href=\"#40975767\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973770\" n=\"53\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I used to be excited about running models locally (LLM, stable diffusion etc) on my Mac, PC, etc. But now I have resigned to the fact that most useful AI compute will mostly be in the cloud. Sure, I can run some slow Llama3 models on my home network, but why bother when it is so cheap or free to run it on a cloud service? I know Apple is pushing local AI models; however, I have serious reservations about the impact on battery performance.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973770&amp;goto=item%3Fid%3D40973339%2340973770\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40975305\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975305\" href=\"vote?id=40975305&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=PostOnce\" class=\"hnuser\">PostOnce</a> <span class=\"age\" title=\"2024-07-16T10:51:21\"><a href=\"item?id=40975305\">1 day ago</a></span> <span id=\"unv_40975305\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975305\" n=\"12\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Maybe you want to conduct experiments that the cloud API doesn't allow for.<p>Perhaps you'd like to plug it into a toolchain that runs faster than API calls can be passed over the network? -- eventually your edge hardware is going to be able to infer a lot faster than the 50ms+ per call to the cloud.</p><p>Maybe you would like to prevent the monopolists from gaining sole control of what may be the most impactful technology of the century.</p><p>Or perhaps you don't want to share your data with Microsoft &amp; Other Evils (formerly known as dont be evil).</p><p>You might just like to work offline. Whole towns go offline, sometimes for days, just because of bad weather. Nevermind war and infrastructure crises.</p><p>Or possibly you don't like that The Cloud model has a fervent, unshakeable belief in the propaganda of its masters. Maybe that propaganda will change one day, and not in your favor. Maybe you'd like to avoid that.</p><p>There are many more reasons in the possibility space than my limited imagination allows for.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975305&amp;goto=item%3Fid%3D40973339%2340975305\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976974\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976974\" href=\"vote?id=40976974&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tarruda\" class=\"hnuser\">tarruda</a> <span class=\"age\" title=\"2024-07-16T14:30:04\"><a href=\"item?id=40976974\">1 day ago</a></span> <span id=\"unv_40976974\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40983782\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976974\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">It is not like strong models are at a point where you can 100% trust their output. It is always necessary to review LLM generated text before using it.<p>I'd rather have a weaker model which I can always rely on being available than a strong model which is hosted by a third party service that can be shut down at any time.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976974&amp;goto=item%3Fid%3D40973339%2340976974\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977755\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977755\" href=\"vote?id=40977755&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Aurornis\" class=\"hnuser\">Aurornis</a> <span class=\"age\" title=\"2024-07-16T16:01:22\"><a href=\"item?id=40977755\">1 day ago</a></span> <span id=\"unv_40977755\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976974\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40983782\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977755\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; I'd rather have a weaker model which I can always rely on being available than a strong model which is hosted by a third party service that can be shut down at any time.<p>Every LLM project I’ve worked with has an abstraction layer for calling hosted LLMs. It’s trivial to implement another adapter to call a different LLM. It’s often does as a fallback, failover strategy.</p><p>There are also services that will merge different providers into a unified API call if you don’t want to handle the complexity on the client.</p><p>It’s really not a problem.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977755&amp;goto=item%3Fid%3D40973339%2340977755\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980976\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980976\" href=\"vote?id=40980976&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=PostOnce\" class=\"hnuser\">PostOnce</a> <span class=\"age\" title=\"2024-07-16T22:38:13\"><a href=\"item?id=40980976\">18 hours ago</a></span> <span id=\"unv_40980976\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40977755\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40983782\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980976\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Suppose you live outside of America and the supermajority of LLM companies are American. You want to ask a question about whisky distillation or abortion or anything else that's legal in your jurisdiction but not in the US, but the LLM won't answer.<p>You've got a plethora of cloud providers, all of them aligned to a foreign country's laws and customs.</p><p>If you can choose between Anthropic, OpenAI, Google, and some others... well, that's really not a choice at all. They're all in California. What good does that do an Austrian or an Australian?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980976&amp;goto=item%3Fid%3D40973339%2340980976\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40983782\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40983782\" href=\"vote?id=40983782&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=neop1x\" class=\"hnuser\">neop1x</a> <span class=\"age\" title=\"2024-07-17T08:55:09\"><a href=\"item?id=40983782\">8 hours ago</a></span> <span id=\"unv_40983782\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976974\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40979491\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40983782\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Also hosted models are often censored and refuse talking about various topics.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40983782&amp;goto=item%3Fid%3D40973339%2340983782\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40979491\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979491\" href=\"vote?id=40979491&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=sharpshadow\" class=\"hnuser\">sharpshadow</a> <span class=\"age\" title=\"2024-07-16T19:27:34\"><a href=\"item?id=40979491\">21 hours ago</a></span> <span id=\"unv_40979491\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40983782\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977688\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979491\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Excellent points and being able to use available hardware in unison is amazing and I guess we are not far away from botnets utilising this kind of technology like they did with mining coins.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979491&amp;goto=item%3Fid%3D40973339%2340979491\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40977688\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977688\" href=\"vote?id=40977688&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=gtirloni\" class=\"hnuser\">gtirloni</a> <span class=\"age\" title=\"2024-07-16T15:55:16\"><a href=\"item?id=40977688\">1 day ago</a></span> <span id=\"unv_40977688\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40979491\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977064\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977688\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\"><i>&gt; eventually your edge hardware is going to be able to infer a lot faster than the 50ms+ per call to the cloud.</i><p>This is interesting. Is that based on any upcoming technology improvement already in the works?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977688&amp;goto=item%3Fid%3D40973339%2340977688\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978089\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978089\" href=\"vote?id=40978089&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=a_t48\" class=\"hnuser\">a_t48</a> <span class=\"age\" title=\"2024-07-16T16:40:21\"><a href=\"item?id=40978089\">1 day ago</a></span> <span id=\"unv_40978089\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40977688\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40979976\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978089\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">GP is likely referring to network latency here. There's a tradeoff between smaller GPUs/etc at home that have no latency to use and beefier hardware in the cloud that have a minimum latency to use.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978089&amp;goto=item%3Fid%3D40973339%2340978089\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40979343\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979343\" href=\"vote?id=40979343&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=yjftsjthsd-h\" class=\"hnuser\">yjftsjthsd-h</a> <span class=\"age\" title=\"2024-07-16T19:10:33\"><a href=\"item?id=40979343\">22 hours ago</a></span> <span id=\"unv_40979343\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40978089\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40979976\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979343\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Sure, but if the model takes multiple seconds to execute, then even 100 milliseconds of network latency seems more or less irrelevant</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979343&amp;goto=item%3Fid%3D40973339%2340979343\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40979976\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979976\" href=\"vote?id=40979976&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=datameta\" class=\"hnuser\">datameta</a> <span class=\"age\" title=\"2024-07-16T20:23:16\"><a href=\"item?id=40979976\">20 hours ago</a></span> <span id=\"unv_40979976\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40977688\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40978089\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977064\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979976\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Comms is also the greatest battery drain for a remote edge system. Local inference can allow for longer operation, or operation with no network infra.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979976&amp;goto=item%3Fid%3D40973339%2340979976\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40977064\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977064\" href=\"vote?id=40977064&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jumpCastle\" class=\"hnuser\">jumpCastle</a> <span class=\"age\" title=\"2024-07-16T14:40:19\"><a href=\"item?id=40977064\">1 day ago</a></span> <span id=\"unv_40977064\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977688\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40983620\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977064\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Aren't services like runpod solve half of these concerns?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977064&amp;goto=item%3Fid%3D40973339%2340977064\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40983620\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40983620\" href=\"vote?id=40983620&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jacooper\" class=\"hnuser\">jacooper</a> <span class=\"age\" title=\"2024-07-17T08:22:15\"><a href=\"item?id=40983620\">8 hours ago</a></span> <span id=\"unv_40983620\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977064\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40983620\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Personally I found the biggest problem for local models is the lack of integrationa, it can't search the web, it can't use wolfram alpha for math, etc<p>LLMs are great as routers, only rarely are they good doing something on their own.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40983620&amp;goto=item%3Fid%3D40973339%2340983620\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40973849\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973849\" href=\"vote?id=40973849&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=wokwokwok\" class=\"hnuser\">wokwokwok</a> <span class=\"age\" title=\"2024-07-16T05:28:14\"><a href=\"item?id=40973849\">1 day ago</a></span> <span id=\"unv_40973849\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975305\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973994\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973849\" n=\"23\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; Sure, I can run some slow Llama3 models on my home network, but why bother when it is so cheap or free to run it on a cloud service?<p>Obvious answer: because it's not free, and it's not cheap.</p><p>If you're playing with a UI library, lets say, QT... would you:</p><p>a) install the community version and play with ($0)</p><p>b) buy a professional license to play with (3460 €/Year)</p><p>Which one do you pick?</p><p>Well, the same goes. It turns out, renting a server large enough to run big (useful, &gt; 8B) models is actually quite expensive. The per-api-call costs of real models (like GPT4) adds up very quickly once you're doing non-trivial work.</p><p>If you're just messing around with the tech, why would you pay $$$$ just to piss around with it and see what you can do?</p><p>Why would you <i>not</i> use a free version running on your old PC / mac / whatever you have lying around?</p><p>&gt; I used to be excited about running models locally</p><p>That's an easy position to be one once you've <i>already done it</i> and figured out, yes, I really want the pro plan to build my $StartUP App.</p><p>If you prefer to pay for an online service and you can afford it, absolutely go for it; but isn't this an enabler for a lot of people to play and explore the tech for $0?</p><p>Isn't having more people who understand this stuff and can make meaningful (non-hype) decisions about when and where to use it good?</p><p>Isn't it nice that if meta released some 400B llama 4 model, most people can play with it, not just the ones with the $7000 mac studio? ...and keep building the open source ecosystem?</p><p>Isn't that great?</p><p>I think it's great.</p><p>Even if you don't want to play, I do.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973849&amp;goto=item%3Fid%3D40973339%2340973849\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976618\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976618\" href=\"vote?id=40976618&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jrm4\" class=\"hnuser\">jrm4</a> <span class=\"age\" title=\"2024-07-16T13:52:06\"><a href=\"item?id=40976618\">1 day ago</a></span> <span id=\"unv_40976618\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976618\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Right, I think people here are <i>vastly</i> underestimating this idea of<p>\"What if I want to play around with really PERSONAL stuff.\"</p><p>I've been keeping a digital journal about my whole life. I plan to throw that thing into an AI to see what happens, and you can be damn sure that it will be local.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976618&amp;goto=item%3Fid%3D40973339%2340976618\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978898\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978898\" href=\"vote?id=40978898&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=monkmartinez\" class=\"hnuser\">monkmartinez</a> <span class=\"age\" title=\"2024-07-16T18:16:58\"><a href=\"item?id=40978898\">23 hours ago</a></span> <span id=\"unv_40978898\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976618\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978898\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Yes, I am with you 100% and keep several LLaMA's on my workstation for that reason. I use Openrouter for everything else. Everything that isn't sensitive goes to one of the big kid models because they are just sooooo much better. LLaMA 400b might be the start of running with the big kids, but I know we are not close with the current available models.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978898&amp;goto=item%3Fid%3D40973339%2340978898\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40973903\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973903\" href=\"vote?id=40973903&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=itake\" class=\"hnuser\">itake</a> <span class=\"age\" title=\"2024-07-16T05:42:23\"><a href=\"item?id=40973903\">1 day ago</a></span> <span id=\"unv_40973903\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976618\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973903\" n=\"17\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I’m a bit confused. Your reasoning doesn’t align with the data you shared.<p>The startup costs for just messing around at home are huge: purchasing a server and gpus, paying for electricity, time spent configuring the api.</p><p>If you want to just mess around, $100 to call the world’s best api is much cheaper than spending $2-7k Mac Studio.</p><p>Even at production level traffic, the ROI on uptime, devops, utilities, etc would take years to recapture the upfront and on-going costs of self-hosting.</p><p>Self hosting will have higher latency and lower throughput.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973903&amp;goto=item%3Fid%3D40973339%2340973903\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974479\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974479\" href=\"vote?id=40974479&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=zeta0134\" class=\"hnuser\">zeta0134</a> <span class=\"age\" title=\"2024-07-16T08:06:50\"><a href=\"item?id=40974479\">1 day ago</a></span> <span id=\"unv_40974479\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973920\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974479\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">You are vastly overestimating the startup cost. For me this week it was literally these commands:<p>pacman -S ollama</p><p>ollama serve</p><p>ollama run llama3</p><p>My basic laptop with about 16 GB of RAM can run the model just fine. It's not fast, but it's reasonably usable for messing around with the tech. That's the \"startup\" cost. Everything else is a matter of pushing scale and performance, and yes that can be expensive, but a novice who doesn't know what they need yet doesn't have to spend tons of money to find out. Almost any PC with a reasonable amount of RAM gets the job done.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974479&amp;goto=item%3Fid%3D40973339%2340974479\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978828\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978828\" href=\"vote?id=40978828&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=monkmartinez\" class=\"hnuser\">monkmartinez</a> <span class=\"age\" title=\"2024-07-16T18:08:42\"><a href=\"item?id=40978828\">23 hours ago</a></span> <span id=\"unv_40978828\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974479\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977682\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978828\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">llama3 at 8billion params is weak sauce for anything serious, it just isn't in the same galaxy as Sonnet 3.5 or GPT-4o. The smaller and faster models like Phi are even worse. Once you progress past asking trivial questions to a point where you need to trust the output a bit more, its not worth effort in time, money and/or sweat effort to run a local model to do it.<p>A novice isn't going to know what they need because they don't know what they don't know. Try asking a question to LLaMA 3 at 8 billion and the same question to LLaMA 3 at 70 billion. There is a night and day difference. Sonnet, Opus and GPT-4o run circles around LLaMA 3 70b. To run LLaMA at 70 billion you need serious horse power as well, likely thousands of dollars in hardware investment. I say it again... the calculus in time, money, and effort isn't favorable to running open models on your own hardware once you pass the novice stage.</p><p>I am not ungrateful that the LLaMA's are available for many different reasons, but there is no comparison between quality of output, time, money and effort. The API's are a bargain when you really break down what it takes to run a serious model.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978828&amp;goto=item%3Fid%3D40973339%2340978828\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980814\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"5\"><img src=\"s.gif\" height=\"1\" width=\"200\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980814\" href=\"vote?id=40980814&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jononor\" class=\"hnuser\">jononor</a> <span class=\"age\" title=\"2024-07-16T22:13:14\"><a href=\"item?id=40980814\">19 hours ago</a></span> <span id=\"unv_40980814\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40978828\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977682\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980814\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Using an LLM as a general purpose knowledge base is only one particular application of an LLM. And on which is probably best served by ChatGPT etc.<p>A lot of other things are possible with LLMs using the context window and completion, thanks to their \"zero shot\" learning capabilities. Which is also what RAG builds upon.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980814&amp;goto=item%3Fid%3D40973339%2340980814\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40977682\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977682\" href=\"vote?id=40977682&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Aurornis\" class=\"hnuser\">Aurornis</a> <span class=\"age\" title=\"2024-07-16T15:54:26\"><a href=\"item?id=40977682\">1 day ago</a></span> <span id=\"unv_40977682\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974479\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40978828\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973920\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977682\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I’m familiar with local models. They’re fine for chatting on unimportant things.<p>They do not compare to the giant models like Claude Sonnet and GPT4 when it comes to trying to use them for complex things.</p><p>I continue to use both local models and the commercial cloud offerings, but I think anyone who suggests that the small local models are on par with the big closed hosted models right now is wishful thinking.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977682&amp;goto=item%3Fid%3D40973339%2340977682\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40973920\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973920\" href=\"vote?id=40973920&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=sudohackthenews\" class=\"hnuser\">sudohackthenews</a> <span class=\"age\" title=\"2024-07-16T05:48:10\"><a href=\"item?id=40973920\">1 day ago</a></span> <span id=\"unv_40973920\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974479\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976715\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973920\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">People have gotten manageable results on all sorts of hardware. People have even squeezed a few tokens/second out of Raspberry PIs. The small models are pretty performant- they get good results on consumer gaming hardware. My 2021 laptop with a 3070m (only 8gb vram) runs 8b models faster than I can read, and even the original M1 chips can run the models fine.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973920&amp;goto=item%3Fid%3D40973339%2340973920\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40979067\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979067\" href=\"vote?id=40979067&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=monkmartinez\" class=\"hnuser\">monkmartinez</a> <span class=\"age\" title=\"2024-07-16T18:36:34\"><a href=\"item?id=40979067\">22 hours ago</a></span> <span id=\"unv_40979067\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973920\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976715\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979067\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">You are right of course.... IF your metric for manageable/useable is measured only tokens per second (tok/s).<p>If your metric is quality of output, time, money and tok/s, there is no comparison; Local models just aren't there yet.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979067&amp;goto=item%3Fid%3D40973339%2340979067\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40976715\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976715\" href=\"vote?id=40976715&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=LorenDB\" class=\"hnuser\">LorenDB</a> <span class=\"age\" title=\"2024-07-16T14:02:17\"><a href=\"item?id=40976715\">1 day ago</a></span> <span id=\"unv_40976715\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973920\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974080\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976715\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">And why would you buy a Mac Studio? You could build a reasonable GPU-accelerated Linux box for well under $1500. For example: <a href=\"https://pcpartpicker.com/guide/BCWG3C/excellent-amd-gamingstreaming-build\" rel=\"nofollow\">https://pcpartpicker.com/guide/BCWG3C/excellent-amd-gamingst...</a></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976715&amp;goto=item%3Fid%3D40973339%2340976715\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40976854\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976854\" href=\"vote?id=40976854&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=J_Shelby_J\" class=\"hnuser\">J_Shelby_J</a> <span class=\"age\" title=\"2024-07-16T14:16:33\"><a href=\"item?id=40976854\">1 day ago</a></span> <span id=\"unv_40976854\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976715\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974080\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976854\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Devs that refuse to move off Apple are severely disadvantaged in the LLM era.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976854&amp;goto=item%3Fid%3D40973339%2340976854\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977042\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"5\"><img src=\"s.gif\" height=\"1\" width=\"200\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977042\" href=\"vote?id=40977042&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jondwillis\" class=\"hnuser\">jondwillis</a> <span class=\"age\" title=\"2024-07-16T14:38:04\"><a href=\"item?id=40977042\">1 day ago</a></span> <span id=\"unv_40977042\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40976854\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974080\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977042\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">lol tell that to the 3 year old laptop with 64 GB of RAM that I use exclusively for local LLMs while dev’ing on my work laptop with 96 GB of RAM…</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977042&amp;goto=item%3Fid%3D40973339%2340977042\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40974080\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974080\" href=\"vote?id=40974080&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=wokwokwok\" class=\"hnuser\">wokwokwok</a> <span class=\"age\" title=\"2024-07-16T06:34:59\"><a href=\"item?id=40974080\">1 day ago</a></span> <span id=\"unv_40974080\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976715\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974080\" n=\"7\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; The startup costs for just messing around at home are huge<p>No, they are zero.</p><p>Most people have extra hardware lying around at home they're not using. It costs nothing but time to install python.</p><p>$100 is not free.</p><p>If you can't be bothered, sure thing, slap down that credit card and spend your $100.</p><p>...but, maybe not so for some people?</p><p>Consider students with no credit card, etc; there are a lot of people with a lot of free time and not a lot of money. Even if <i>you</i> don't want to use it do you do seriously think this project is totally valueless for everyone?</p><p>Maybe, it's not for you. Not everything has to be for everyone.</p><p>You are, maybe, just not the target audience here?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974080&amp;goto=item%3Fid%3D40973339%2340974080\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977712\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977712\" href=\"vote?id=40977712&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Aurornis\" class=\"hnuser\">Aurornis</a> <span class=\"age\" title=\"2024-07-16T15:57:42\"><a href=\"item?id=40977712\">1 day ago</a></span> <span id=\"unv_40977712\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974080\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974111\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977712\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; You are, maybe, just not the target audience here?<p>The difference between an open model running on a $100 computer and the output from GPT4 or Claude Sonnet is huge.</p><p>I use local and cloud models. The difference in productivity and accuracy between what I can run locally and what I can get for under $100 of API calls per month is huge once you get past basic playing around with chat. It’s not even close right now.</p><p>So I think actually you are not the target audience for what the parent comments are taking about. If you don’t need cutting edge performance then it’s fun to play with local, open, small models. If the goal is to actually use LLMs for productivity in one way or another, spending money on the cloud providers is a far better investment.</p><p>Exceptions of course for anything that is privacy-sensitive, but you’re still sacrificing quality by using local models. It’s not really up for debate that the large hosted models are better than what you’d get from running a 7B open model locally.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977712&amp;goto=item%3Fid%3D40973339%2340977712\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40974111\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974111\" href=\"vote?id=40974111&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=lynx23\" class=\"hnuser\">lynx23</a> <span class=\"age\" title=\"2024-07-16T06:41:48\"><a href=\"item?id=40974111\">1 day ago</a></span> <span id=\"unv_40974111\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974080\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977712\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974111\" n=\"5\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c73\">And its not entitled to cliam that \"Most people have extra hardware lying around at home\".  Your story doesn't sound plausible at all.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974111&amp;goto=item%3Fid%3D40973339%2340974111\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974927\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"5\"><img src=\"s.gif\" height=\"1\" width=\"200\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974927\" href=\"vote?id=40974927&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=bryanrasmussen\" class=\"hnuser\">bryanrasmussen</a> <span class=\"age\" title=\"2024-07-16T09:43:12\"><a href=\"item?id=40974927\">1 day ago</a></span> <span id=\"unv_40974927\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974111\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974150\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974927\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Most people who would want to be running machine learning models probably have some hardware at home that can handle a slow task for playing around and determining if it is worthwhile to pay out for something more performant.<p>This is undoubtedly entitled, but thinking to yourself huh, I think it's time to try out some of this machine learning stuff is a pretty inherently entitled thing to do.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974927&amp;goto=item%3Fid%3D40973339%2340974927\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40974150\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"5\"><img src=\"s.gif\" height=\"1\" width=\"200\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974150\" href=\"vote?id=40974150&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=wokwokwok\" class=\"hnuser\">wokwokwok</a> <span class=\"age\" title=\"2024-07-16T06:50:59\"><a href=\"item?id=40974150\">1 day ago</a></span> <span id=\"unv_40974150\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974111\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974927\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974150\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This project is <i>literally</i> aiming to run on devices like old phones.<p>I don't think having an old phone is particularly entitled.</p><p>I think casually slapping down $100 on whim to play with an API... probably, yeah.</p><p>/shrug</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974150&amp;goto=item%3Fid%3D40973339%2340974150\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974177\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"6\"><img src=\"s.gif\" height=\"1\" width=\"240\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974177\" href=\"vote?id=40974177&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=itake\" class=\"hnuser\">itake</a> <span class=\"age\" title=\"2024-07-16T06:57:26\"><a href=\"item?id=40974177\">1 day ago</a></span> <span id=\"unv_40974177\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974150\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974177\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">According to this tweet, Llama 3 costs about $0.20 per Million tokens using an M2.<p><a href=\"https://x.com/awnihannun/status/1786069640948719956\" rel=\"nofollow\">https://x.com/awnihannun/status/1786069640948719956</a></p><p>In comparison, GPT3.5-turbo costs $0.50 per million tokens.</p><p>Do you think an old iPhone will less than 2x efficient?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974177&amp;goto=item%3Fid%3D40973339%2340974177\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40975633\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"7\"><img src=\"s.gif\" height=\"1\" width=\"280\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975633\" href=\"vote?id=40975633&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=nightski\" class=\"hnuser\">nightski</a> <span class=\"age\" title=\"2024-07-16T11:46:24\"><a href=\"item?id=40975633\">1 day ago</a></span> <span id=\"unv_40975633\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974177\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975633\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">FWIW depends on cost of power.  Where I live cost of power is less than half the stated average.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975633&amp;goto=item%3Fid%3D40973339%2340975633\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                                          <tr class=\"athing comtr\" id=\"40976262\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976262\" href=\"vote?id=40976262&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=nl\" class=\"hnuser\">nl</a> <span class=\"age\" title=\"2024-07-16T13:14:46\"><a href=\"item?id=40976262\">1 day ago</a></span> <span id=\"unv_40976262\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973903\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973887\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976262\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; Well, the same goes. It turns out, renting a server large enough to run big (useful, &gt; 8B) models is actually quite expensive. The per-api-call costs of real models (like GPT4) adds up very quickly once you're doing non-trivial work.<p>I run my own models, but the truth is most of the time I just use an API provider.</p><p>TogetherAI and Groq both have free offers that are generous enough I haven't used them up in 6 months of experimentation and TogetherAI in particular has more models and gets new models up quicker than I can try them myself.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976262&amp;goto=item%3Fid%3D40973339%2340976262\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40973887\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973887\" href=\"vote?id=40973887&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=FeepingCreature\" class=\"hnuser\">FeepingCreature</a> <span class=\"age\" title=\"2024-07-16T05:36:00\"><a href=\"item?id=40973887\">1 day ago</a></span> <span id=\"unv_40973887\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976262\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977655\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973887\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I just prepay $20/mo to openrouter.ai and can instantly play with every model, no further signup required.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973887&amp;goto=item%3Fid%3D40973339%2340973887\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40977655\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977655\" href=\"vote?id=40977655&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Aurornis\" class=\"hnuser\">Aurornis</a> <span class=\"age\" title=\"2024-07-16T15:51:47\"><a href=\"item?id=40977655\">1 day ago</a></span> <span id=\"unv_40977655\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973887\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973994\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977655\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c5a\">&gt; Why would you not use a free version running on your old PC / mac / whatever you have lying around?<p>Because the old PC lying around can’t come anywhere near the abilities or performance of the hosted AI compute providers. Orders of magnitudes of difference.</p><p>The parent commenter is correct: If you want cutting edge performance, there’s no replacement for the hosted solutions right now.</p><p>Running models locally is fun for playing around and experimenting, but there is no comparison between what you can run on an old PC lying around and what you can get from a hosted cluster of cutting edge hardware that offers cheap output priced per API call.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977655&amp;goto=item%3Fid%3D40973339%2340977655\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                            <tr class=\"athing comtr\" id=\"40973994\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973994\" href=\"vote?id=40973994&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=dotancohen\" class=\"hnuser\">dotancohen</a> <span class=\"age\" title=\"2024-07-16T06:13:46\"><a href=\"item?id=40973994\">1 day ago</a></span> <span id=\"unv_40973994\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973849\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973789\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973994\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I have found many similarities between home AI and home astronomy. The equipment needed to get really good performance is far beyond that available to the home user, however intellectually satisfying results can be had at home as a hobby. But certainly not professional results.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973994&amp;goto=item%3Fid%3D40973339%2340973994\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40975660\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975660\" href=\"vote?id=40975660&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=grugagag\" class=\"hnuser\">grugagag</a> <span class=\"age\" title=\"2024-07-16T11:51:00\"><a href=\"item?id=40975660\">1 day ago</a></span> <span id=\"unv_40975660\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973994\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973789\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975660\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">When learning and experimenting it could make a difference.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975660&amp;goto=item%3Fid%3D40973339%2340975660\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40973789\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973789\" href=\"vote?id=40973789&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Cantinflas\" class=\"hnuser\">Cantinflas</a> <span class=\"age\" title=\"2024-07-16T05:10:19\"><a href=\"item?id=40973789\">1 day ago</a></span> <span id=\"unv_40973789\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973994\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974443\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973789\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Why bother running models locally? Privacy, for once, or censorship resistance.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973789&amp;goto=item%3Fid%3D40973339%2340973789\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40973826\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973826\" href=\"vote?id=40973826&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=seasonman\" class=\"hnuser\">seasonman</a> <span class=\"age\" title=\"2024-07-16T05:20:34\"><a href=\"item?id=40973826\">1 day ago</a></span> <span id=\"unv_40973826\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973789\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973884\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973826\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Also customizability. Sure, you can fine-tune the cloud hosted models (to a certain degree of freedom), but it will probably be expensive, inefficient, difficult and unmaintainable.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973826&amp;goto=item%3Fid%3D40973339%2340973826\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40973884\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973884\" href=\"vote?id=40973884&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=hanniabu\" class=\"hnuser\">hanniabu</a> <span class=\"age\" title=\"2024-07-16T05:35:37\"><a href=\"item?id=40973884\">1 day ago</a></span> <span id=\"unv_40973884\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973789\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973826\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974443\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973884\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">And offline access</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973884&amp;goto=item%3Fid%3D40973339%2340973884\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40974443\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974443\" href=\"vote?id=40974443&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=dsign\" class=\"hnuser\">dsign</a> <span class=\"age\" title=\"2024-07-16T07:58:09\"><a href=\"item?id=40974443\">1 day ago</a></span> <span id=\"unv_40974443\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973789\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974454\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974443\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">For my advanced spell-checking use-case[^1], local LLMs are, sadly, not state-of-the-art. But their $0 price-point is excellent to analyze lots of sentences and catch the most obvious issues. With some clever hacking, the most difficult cases can be handled by GPT4o and Claude. I'm glad there is a wide variety of options.<p>[^1] Hey! If you know of spell-checking-tuned LLM models, I'm all ears (eyes).</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974443&amp;goto=item%3Fid%3D40973339%2340974443\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40975095\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975095\" href=\"vote?id=40975095&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=bruce343434\" class=\"hnuser\">bruce343434</a> <span class=\"age\" title=\"2024-07-16T10:16:50\"><a href=\"item?id=40975095\">1 day ago</a></span> <span id=\"unv_40975095\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974443\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974454\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975095\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I think the floating point encoding of LLMs is inherently lossy, add to that the way tokenization works. The LLMs I've worked with \"ignore\" bad spelling and correctly interpret misspelled words. I'm guessing that for spelling LLMs, you'd want tokenization at the character level, rather than a byte pair encoding.<p>You could probably train any recent LLM to be better than a human at spelling correction though, where \"better\" might be a vague combination of faster, cheaper, and acceptable loss of accuracy. Or maybe slightly more accurate.</p><p>(A lot of people hate on LLMs for not being perfect, I don't get it. LLMs are just a tool with their own set of trade offs, no need to get rabid either for or against them. Often, things just need to be \"good enough\". Maybe people on this forum have higher standards than average, and can not deal with the frustration of that cognitive dissonance)</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975095&amp;goto=item%3Fid%3D40973339%2340975095\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40974454\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974454\" href=\"vote?id=40974454&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Hihowarewetoday\" class=\"hnuser\">Hihowarewetoday</a> <span class=\"age\" title=\"2024-07-16T07:59:54\"><a href=\"item?id=40974454\">1 day ago</a></span> <span id=\"unv_40974454\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974443\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977769\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974454\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I'm not sure why you have resigned?<p>If you don't care about running it locally, just spend it online. Everything is good.</p><p>But you can run it locally already. Is it cheap? No. Are we still in the beginning? yes. We are still in a phase were this is a pure luxury and just getting into it by buying a 4090, is still relativly cheap in my opinion.</p><p>Why running it locally you ask? I personally think running anythingllm and similiar frameworks on your own local data is interesting.</p><p>But im pretty sure in a few years you will be able to buy cheaper ml chips for running models locally fast and cheap.</p><p>Btw. aat least i don't know a online service which is uncensored, has a lot of loras as choice and is cost effective. For just playing around with LLMs for sure there are plenty of services.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974454&amp;goto=item%3Fid%3D40973339%2340974454\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40977769\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977769\" href=\"vote?id=40977769&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=diego_sandoval\" class=\"hnuser\">diego_sandoval</a> <span class=\"age\" title=\"2024-07-16T16:02:44\"><a href=\"item?id=40977769\">1 day ago</a></span> <span id=\"unv_40977769\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974454\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40976595\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977769\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; why bother when it is so cheap or free to run it on a cloud service?<p>For the same reasons that we bother to use Open Source software instead of proprietary software.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977769&amp;goto=item%3Fid%3D40973339%2340977769\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40976595\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40976595\" href=\"vote?id=40976595&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jrm4\" class=\"hnuser\">jrm4</a> <span class=\"age\" title=\"2024-07-16T13:48:50\"><a href=\"item?id=40976595\">1 day ago</a></span> <span id=\"unv_40976595\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977769\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974136\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40976595\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">What do you mean by <i>useful</i> here?<p>I'm saying because I've had the exact OPPOSITE thought.  The intersection of Moore's Law and the likelihood that these things won't end up as some big unified singularity brain and instead little customized use cases make me think that running at home/office will perhaps be just as appealing.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40976595&amp;goto=item%3Fid%3D40973339%2340976595\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40974136\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974136\" href=\"vote?id=40974136&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=friendly_chap\" class=\"hnuser\">friendly_chap</a> <span class=\"age\" title=\"2024-07-16T06:46:49\"><a href=\"item?id=40974136\">1 day ago</a></span> <span id=\"unv_40974136\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40976595\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977714\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974136\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">We are running smaller models with software we wrote (self plug alert: <a href=\"https://github.com/singulatron/singulatron\">https://github.com/singulatron/singulatron</a>) with great success. There are obvious mistakes these models make (such as the one in our repo image - haha) sometimes but they can also be surprisingly versatile in areas you don't expect them to be, like coding.<p>Our demo site uses two NVIDIA GeForce RTX 3090 and our whole team is hammering it all day. The only problem is occasionally high GPU temperature.</p><p>I don't think the picture is as bleak as you paint. I actually expect Moore's Law and better AI architectures to bring on a self-hosted AI revolution in the next few years.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974136&amp;goto=item%3Fid%3D40973339%2340974136\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40977714\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977714\" href=\"vote?id=40977714&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=dws\" class=\"hnuser\">dws</a> <span class=\"age\" title=\"2024-07-16T15:58:17\"><a href=\"item?id=40977714\">1 day ago</a></span> <span id=\"unv_40977714\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974136\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973817\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977714\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; Sure, I can run some slow Llama3 models on my home network, but why bother when it is so cheap or free to run it on a cloud service?<p>Running locally, you can change the system prompt. I have Gemma set up on a spare NUC, and changed the system prompt from \"helpful\" to \"snarky\" and \"kind, honest\" to \"brutally honest\". Having an LLM that will roll its eyes at you and say \"whatever\" is refreshing.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977714&amp;goto=item%3Fid%3D40973339%2340977714\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40973817\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973817\" href=\"vote?id=40973817&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=nhod\" class=\"hnuser\">nhod</a> <span class=\"age\" title=\"2024-07-16T05:17:20\"><a href=\"item?id=40973817\">1 day ago</a></span> <span id=\"unv_40973817\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977714\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977268\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973817\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Is this a hunch, or do you know of some data to back up your reservations?<p>Copilot+ PC’s, which all run models locally, have the best battery life of any portable PC devices, ever.</p><p>These devices have in turn taken a page out of Apple Silicon’s playbook. Apple has the benefit of deep hardware and software integration that no one else has, and is obsessive about battery life.</p><p>It is reasonable to think that battery life will not be impacted much.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973817&amp;goto=item%3Fid%3D40973339%2340973817\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40973869\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973869\" href=\"vote?id=40973869&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=fragmede\" class=\"hnuser\">fragmede</a> <span class=\"age\" title=\"2024-07-16T05:31:13\"><a href=\"item?id=40973869\">1 day ago</a></span> <span id=\"unv_40973869\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40973817\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977268\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973869\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">That doesn't seem totally reasonable. The battery life of an iphone is pretty great if you're not actually using it, but if you're using the device hard, it gets hot to the touch, along with the battery getting drained. playing resource intensive video games, maxing out the *PU won't stop and let the device sleep at all, and has a noticable hit on battery life. Where inference takes a lot of compute to perform, it's hard to imagine inference being totally free, battery-wise. It probably won't be as hard on the device as playing specific video games non-stop, but I get into phone conversations with ChatGPT as it is, so I can imagine that being a concern if you're already low on battery.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973869&amp;goto=item%3Fid%3D40973339%2340973869\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40977268\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977268\" href=\"vote?id=40977268&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=aftbit\" class=\"hnuser\">aftbit</a> <span class=\"age\" title=\"2024-07-16T15:03:32\"><a href=\"item?id=40977268\">1 day ago</a></span> <span id=\"unv_40977268\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973817\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973806\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977268\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">What if you want to create transcripts for 100s of hours of private recorded audio? I for one do not want to share that with the cloud providers and have it get used as training data or be subject to warrentless search under the third party doctrine. Or what if you want to run a spicy Stable Diffusion fine-tune that you'd rather not have associated with your name in case the anti-porn fascists take over? I feel like there are dozens of situations where the cost is really not the main reason to prefer a local solution.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977268&amp;goto=item%3Fid%3D40973339%2340977268\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40973806\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973806\" href=\"vote?id=40973806&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=bongodongobob\" class=\"hnuser\">bongodongobob</a> <span class=\"age\" title=\"2024-07-16T05:14:32\"><a href=\"item?id=40973806\">1 day ago</a></span> <span id=\"unv_40973806\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977268\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40979385\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973806\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I have a 2 year old Thinkpad and I wouldn't necessarily call llama3 slow on it. It's not as fast as ChatGPT but certainly serviceable. This should only help.<p>Not sure why your throwing your hands up because this is a step towards solving your problem.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973806&amp;goto=item%3Fid%3D40973339%2340973806\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40979385\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979385\" href=\"vote?id=40979385&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=cess11\" class=\"hnuser\">cess11</a> <span class=\"age\" title=\"2024-07-16T19:15:36\"><a href=\"item?id=40979385\">22 hours ago</a></span> <span id=\"unv_40979385\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973806\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979385\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I don't want people I don't know snooping around in my experiments.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979385&amp;goto=item%3Fid%3D40973339%2340979385\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40975040\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975040\" href=\"vote?id=40975040&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=matyaskzs\" class=\"hnuser\">matyaskzs</a> <span class=\"age\" title=\"2024-07-16T10:05:39\"><a href=\"item?id=40975040\">1 day ago</a></span> <span id=\"unv_40975040\"></span>          <span class=\"navs\">\n             | <a href=\"#40973770\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40980865\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975040\" n=\"5\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Cloud cannot be beaten on compute / price, but moving to local could solve privacy issues and the world needs a second amendment for compute anyway.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975040&amp;goto=item%3Fid%3D40973339%2340975040\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40981712\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40981712\" href=\"vote?id=40981712&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=dijit\" class=\"hnuser\">dijit</a> <span class=\"age\" title=\"2024-07-17T00:59:39\"><a href=\"item?id=40981712\">16 hours ago</a></span> <span id=\"unv_40981712\"></span>          <span class=\"navs\">\n             | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975776\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40981712\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; Cloud cannot be beaten on compute / price<p>Sorry, I can't let misinformation like that slide.</p><p>Cloud cost/benefit ratio is <i>not</i> good in <i>many</i> circumstances.</p><p>For hobbyists it works well because you run your job for very brief periods and renting is much cheaper than buying in those cases. Similarly, if your business usage is so low as to be effectively run once per day then cloud has major benefits.</p><p>However, if you are doing any kind of work that consumes more than 8hrs of computer time in a day, cloud is going to start being much more expensive.</p><p>The exact cost/benefit depends on the SKU and I'm mostly talking about CPU/Memory/Storage- for managed services like databases it's significantly worse, and I'm comparing to rented servers not self-hosting at home, which is <i>significantly cheaper</i> still.</p><p>Local hardware has downsides (availability, inflexibility), but it's faster and cheaper in almost all <i>real workload</i> scenarios where the compute would otherwise be completely idle/turned off &gt;90% of the time.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40981712&amp;goto=item%3Fid%3D40973339%2340981712\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40975776\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975776\" href=\"vote?id=40975776&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=CuriouslyC\" class=\"hnuser\">CuriouslyC</a> <span class=\"age\" title=\"2024-07-16T12:08:51\"><a href=\"item?id=40975776\">1 day ago</a></span> <span id=\"unv_40975776\"></span>          <span class=\"navs\">\n             | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40981712\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40980865\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975776\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">You can beat gpt4/claude in terms of price/performance for most things by a mile using fine tuned models running in a colo.  Those extra parameters give the chatbots the ability to understand malformed input and to provide off the cuff answers about almost anything, but small models can be just as smart about limited domains.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975776&amp;goto=item%3Fid%3D40973339%2340975776\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977708\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977708\" href=\"vote?id=40977708&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=ComputerGuru\" class=\"hnuser\">ComputerGuru</a> <span class=\"age\" title=\"2024-07-16T15:57:26\"><a href=\"item?id=40977708\">1 day ago</a></span> <span id=\"unv_40977708\"></span>          <span class=\"navs\">\n             | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40975776\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980865\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977708\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The problem is that once you say “fine tuned” then you have immediately slashed the user base down to virtually nothing. You need to fine-tune per-task and usually per-user (or org). There is no good way to scale that.<p>Apple can fine-tune a local LLM to respond to a catalog of common interactions and requests but it’s hard to see anyone else deploying fine-tuned models for non-technical audiences or even for their own purposes when most of their needs are one-off and not recurring cases of the same thing.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977708&amp;goto=item%3Fid%3D40973339%2340977708\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978390\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978390\" href=\"vote?id=40978390&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=CuriouslyC\" class=\"hnuser\">CuriouslyC</a> <span class=\"age\" title=\"2024-07-16T17:17:58\"><a href=\"item?id=40978390\">1 day ago</a></span> <span id=\"unv_40978390\"></span>          <span class=\"navs\">\n             | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40977708\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980865\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978390\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Not necessarily, you can fine tune on a general domain of knowledge (people already do this and open source the results) then use on device RAG to give it specific knowledge in the domain.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978390&amp;goto=item%3Fid%3D40973339%2340978390\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                              <tr class=\"athing comtr\" id=\"40980865\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980865\" href=\"vote?id=40980865&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=fudged71\" class=\"hnuser\">fudged71</a> <span class=\"age\" title=\"2024-07-16T22:21:33\"><a href=\"item?id=40980865\">18 hours ago</a></span> <span id=\"unv_40980865\"></span>          <span class=\"navs\">\n             | <a href=\"#40975040\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40980399\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980865\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Since this is best over a local network, I wonder how easy you could make the crowdsourcing aspect of this. How could you make it simple enough for everyone that's physically in your office to join a network to train overnight? Or get everyone at a conference to scan a QR code to contribute to a domain specific model.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980865&amp;goto=item%3Fid%3D40973339%2340980865\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980941\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980941\" href=\"vote?id=40980941&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T22:32:21\"><a href=\"item?id=40980941\">18 hours ago</a></span> <span id=\"unv_40980941\"></span>          <span class=\"navs\">\n             | <a href=\"#40980865\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980399\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980941\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">That’s where we want to get eventually. There’s a lot of work that needs to be done but I’m confident we’ll get there. Give us 3 months and it’ll be as simple as running Dropbox.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980941&amp;goto=item%3Fid%3D40973339%2340980941\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40980399\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980399\" href=\"vote?id=40980399&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Jayakumark\" class=\"hnuser\">Jayakumark</a> <span class=\"age\" title=\"2024-07-16T21:15:21\"><a href=\"item?id=40980399\">20 hours ago</a></span> <span id=\"unv_40980399\"></span>          <span class=\"navs\">\n             | <a href=\"#40980865\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40982323\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980399\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Just got <a href=\"https://github.com/distantmagic/paddler\">https://github.com/distantmagic/paddler</a> working across 2 machines on windows, for load balancing, This will be next level and useful for Llama 400B to run across multiple machines. But looks like windows support is not there yet.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980399&amp;goto=item%3Fid%3D40973339%2340980399\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40982323\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40982323\" href=\"vote?id=40982323&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=gnicholas\" class=\"hnuser\">gnicholas</a> <span class=\"age\" title=\"2024-07-17T03:36:13\"><a href=\"item?id=40982323\">13 hours ago</a></span> <span id=\"unv_40982323\"></span>          <span class=\"navs\">\n             | <a href=\"#40980399\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977134\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40982323\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This is great! I really wish Apple allowed your device to query a model you host instead of skipping to their cloud (or OpenAI). I'd love to have a Studio Pro running at home, and have my iPhone, iPad, Mac, and HomePod be able to access it instead of going to the cloud. That way I could have even more assured privacy, and I could choose what model I want to run.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40982323&amp;goto=item%3Fid%3D40973339%2340982323\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40982483\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40982483\" href=\"vote?id=40982483&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-17T04:14:25\"><a href=\"item?id=40982483\">13 hours ago</a></span> <span id=\"unv_40982483\"></span>          <span class=\"navs\">\n             | <a href=\"#40982323\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977134\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40982483\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Do you mean with Apple Intelligence? You can already query models you host from Apple using exo or even just local on-device inference.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40982483&amp;goto=item%3Fid%3D40973339%2340982483\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40982728\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40982728\" href=\"vote?id=40982728&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=gnicholas\" class=\"hnuser\">gnicholas</a> <span class=\"age\" title=\"2024-07-17T05:03:21\"><a href=\"item?id=40982728\">12 hours ago</a></span> <span id=\"unv_40982728\"></span>          <span class=\"navs\">\n             | <a href=\"#40982323\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40982483\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977134\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40982728\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Does this work with Siri? I'm not running the beta so am not familiar with the features and limitations, but I thought that it was either answering based on on-device inference (using a closed model) or Apple's cloud (using a model you can't choose). My understanding is that you can ask OpenAI via an integration they've built, and that in the future you may be able to reach out to other hosted models. But I didn't see anything about being able to seamlessly reach out to your own locally-hosted models, either for Siri backup or anything else. But like I said, I'm not running the beta!</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40982728&amp;goto=item%3Fid%3D40973339%2340982728\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40977134\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977134\" href=\"vote?id=40977134&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=makmanalp\" class=\"hnuser\">makmanalp</a> <span class=\"age\" title=\"2024-07-16T14:48:05\"><a href=\"item?id=40977134\">1 day ago</a></span> <span id=\"unv_40977134\"></span>          <span class=\"navs\">\n             | <a href=\"#40982323\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40984059\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977134\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Question - if large clusters are reporting that they're seeing gains from using RDMA networks because communication overhead is a bottleneck, how is it possible that this thing is not massively bottlenecked running over a home network?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977134&amp;goto=item%3Fid%3D40973339%2340977134\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977376\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977376\" href=\"vote?id=40977376&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=DistractionRect\" class=\"hnuser\">DistractionRect</a> <span class=\"age\" title=\"2024-07-16T15:18:32\"><a href=\"item?id=40977376\">1 day ago</a></span> <span id=\"unv_40977376\"></span>          <span class=\"navs\">\n             | <a href=\"#40977134\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977594\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977376\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I suspect that most of the devices you'd expect to find in your consumer cluster are too small/slow to saturate the link.<p>Edit: it's also a matter of scale. You probably have a small number of small/slow devices in a consumer network versus a lot of large/fast devices in your enterprise cluster.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977376&amp;goto=item%3Fid%3D40973339%2340977376\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40977594\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977594\" href=\"vote?id=40977594&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=derefr\" class=\"hnuser\">derefr</a> <span class=\"age\" title=\"2024-07-16T15:44:11\"><a href=\"item?id=40977594\">1 day ago</a></span> <span id=\"unv_40977594\"></span>          <span class=\"navs\">\n             | <a href=\"#40977134\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977376\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40984059\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977594\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I haven't looked into exactly what this project is doing, but here's my understanding:<p>Inference across O(N) pre-trained hidden layers isn't exactly an \"embarrassingly parallel\" problem, but it <i>is</i> an \"embarrassingly pipeline-able\" problem (in the CPU sense of \"pipelining.\") Each device can keep just one or a few layers hot in their own VRAM; and also only needs to send and receive one small embedding (&lt;1MB) vector per timestep — which is so trivial that it's easily achievable in realtime even if all the devices are on wi-fi, talking to the same router, in your \"noisy\" apartment where 100 other neighbours are on the same bands.</p><p>(To put it another way: running a single inference job, has more forgiving realtime latency+throughput requirements than game streaming!)</p><p>Assuming that you have a model that's too big for any of your home machines to individually hold; and that all you care about is performance for single-concurrent-request inference on that model — then <i>in theory</i>, you just need <i>one</i> GPU of one node of your homespun Beowulf GPU cluster to have enough VRAM to keep the single largest layer of your model always-hot; and then other smaller devices can handle keeping the smaller layers always-hot. And the result <i>should</i> be faster than \"overloading\" that same model on that single largest-VRAM device and having some layers spill to CPU, or worse yet, having the GPU have to swap layers in and out repeatedly with each inference step.</p><p>(Also, if you're wondering, in the case where a single machine/node has multiple GPUs — or a GPU+VRAM and also a CPU+RAM! — you can treat this as no different than if these were multiple independent nodes, that just-so-happen to have a very efficient pipeline communication channel between them. As the VRAM+computation cost of running inference far outweighs the communication overhead of forward propagation during inference, a home-network inference-pipelining cluster scheduler like this project, would still likely \"schedule\" the model's layers purely in consideration of the properties of the individual GPU+VRAM (or CPU+RAM), rather than bothering to care about placement.)</p><p>---</p><p>That being said, AFAIK training <i>is</i> \"pipeline parallelizable\" exactly as inference is. And people training models <i>do</i> do this — but almost always only across multiple top-of-the-line GPUs in one machine; not across multiple machines.</p><p>When you think about what pipelining achieves for training — all you get is either:</p><p>1. the ability to use a bunch of small-aggregate-VRAM nodes to achieve the aggregate training capacity of fewer, larger-aggregate-VRAM nodes — but with more power consumption = higher OpEx; and where also, if you scale this to O(N), then you're dumping a quadratic amount of layer-propagation data (which is now both forward-prop <i>and</i> backprop data, and backprop data is bigger!) over what would likely be a shared network just to make this work. (If it's <i>not</i> a shared network — i.e. if it's Infiniband/other RDMA — then why did you spend all that CapEx for your network and not on your GPUs!?)</p><p>2. the ability to pipeline a bunch of large-aggregate-VRAM nodes together to train a model that will then <i>never</i> be able to be deployed onto any single node in existence, but can instead <i>only</i> exist as a \"pipelined inference model\" that hogs O(log N) nodes of your cluster at a time for any inference run. Which makes cluster scheduling hell (if you aren't just permanently wiring the scheduler to treat O(log N)-node groups as single \"hyper-nodes\"); makes it so that you'll never be able to practically open-source the model in a way anybody but other bigcorps could ever run it (if that's something you care about); and very likely means you're cutting the concurrent-inference-request-serving capacity of your huge expensive GPU cluster by O(log N)... which the product team that allowed that cluster to be budgeted is <i>really</i> not gonna like.</p><p>That being said, I imagine at some point one of these proprietary \"Inference-as-a-Service\" models <i>has</i> been trained at a layer size that puts it into pipelined-inference-only territory, <i>temporarily</i>. Doing so would be the ML engineer's equivalent to the CPU engineer's \"we have no fundamentally clever advance, so this quarter we'll just crank up the clock frequency and deal with the higher TDP.\" (Heck, maybe GPT-4o is one of these.)</p><p>---</p><p>What people with GPU clusters <i>want</i>, is 1. for the output of the process to be a model that runs on a single (perhaps multi-GPU) node; and 2. for the process itself to be mostly-shared-nothing with as little cross-node communication burden as possible (such that it's just a question of building highly <i>internally</i> communication-efficient nodes, not so much highly-communication-efficient clusters.)</p><p>And both of those goals are achieved by sizing models so that they fit within a single node; continuously fanning out streams of training data to those nodes; and then periodically fanning back in model-weights (or model-weight deltas) in an AllReduce operation, to merge the learning of O(N) independently-training nodes to become the new baseline for those nodes.</p><p>(If you'll note, this architecture doesn't put <i>any</i> latency requirements on the network, only some monstrous <i>throughput</i> requirements [at the fan-in step] — which makes it a <i>lot</i> easier to design for.)</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977594&amp;goto=item%3Fid%3D40973339%2340977594\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40984059\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40984059\" href=\"vote?id=40984059&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=rbanffy\" class=\"hnuser\">rbanffy</a> <span class=\"age\" title=\"2024-07-17T09:46:36\"><a href=\"item?id=40984059\">7 hours ago</a></span> <span id=\"unv_40984059\"></span>          <span class=\"navs\">\n             | <a href=\"#40977134\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975144\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40984059\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The all important question:<p>When there’s only one device left on the network, will it sing Daisy Bell?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40984059&amp;goto=item%3Fid%3D40973339%2340984059\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40975144\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975144\" href=\"vote?id=40975144&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=pierrefermat1\" class=\"hnuser\">pierrefermat1</a> <span class=\"age\" title=\"2024-07-16T10:24:01\"><a href=\"item?id=40975144\">1 day ago</a></span> <span id=\"unv_40975144\"></span>          <span class=\"navs\">\n             | <a href=\"#40984059\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40983516\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975144\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Would be great if we could get some benchmarks on commonly available hardware setups.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975144&amp;goto=item%3Fid%3D40973339%2340975144\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980340\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980340\" href=\"vote?id=40980340&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=festive-minsky\" class=\"hnuser\">festive-minsky</a> <span class=\"age\" title=\"2024-07-16T21:07:14\"><a href=\"item?id=40980340\">20 hours ago</a></span> <span id=\"unv_40980340\"></span>          <span class=\"navs\">\n             | <a href=\"#40975144\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975201\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980340\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">So I just tried with 2x macbook pros (M2 64GB &amp; M3 128GB) and it was exactly the same speed as with just 1 macbook pro (M2 64GB)\nNot exactly a common setup but at least it's something</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980340&amp;goto=item%3Fid%3D40973339%2340980340\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980488\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980488\" href=\"vote?id=40980488&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T21:28:00\"><a href=\"item?id=40980488\">19 hours ago</a></span> <span id=\"unv_40980488\"></span>          <span class=\"navs\">\n             | <a href=\"#40975144\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40980340\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975201\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980488\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Could you create a GitHub issue? There's a lot of work we'd like to do to improve this.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980488&amp;goto=item%3Fid%3D40973339%2340980488\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40975201\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975201\" href=\"vote?id=40975201&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=pharrington\" class=\"hnuser\">pharrington</a> <span class=\"age\" title=\"2024-07-16T10:33:09\"><a href=\"item?id=40975201\">1 day ago</a></span> <span id=\"unv_40975201\"></span>          <span class=\"navs\">\n             | <a href=\"#40975144\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980340\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40983516\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975201\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I'm sure someone will show their benchmarks in a couple years!</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975201&amp;goto=item%3Fid%3D40973339%2340975201\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40983516\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40983516\" href=\"vote?id=40983516&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=throwaway2562\" class=\"hnuser\">throwaway2562</a> <span class=\"age\" title=\"2024-07-17T08:02:46\"><a href=\"item?id=40983516\">9 hours ago</a></span> <span id=\"unv_40983516\"></span>          <span class=\"navs\">\n             | <a href=\"#40975144\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975426\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40983516\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">How long before the accursed crypto kids try to tokenise token generation with Exo clusters?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40983516&amp;goto=item%3Fid%3D40973339%2340983516\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40984095\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40984095\" href=\"vote?id=40984095&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=rbanffy\" class=\"hnuser\">rbanffy</a> <span class=\"age\" title=\"2024-07-17T09:51:49\"><a href=\"item?id=40984095\">7 hours ago</a></span> <span id=\"unv_40984095\"></span>          <span class=\"navs\">\n             | <a href=\"#40983516\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40983630\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40984095\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Crypto kids driving development of general purpose hardware is a win-win scenario</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40984095&amp;goto=item%3Fid%3D40973339%2340984095\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40983630\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40983630\" href=\"vote?id=40983630&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=rjzzleep\" class=\"hnuser\">rjzzleep</a> <span class=\"age\" title=\"2024-07-17T08:24:22\"><a href=\"item?id=40983630\">8 hours ago</a></span> <span id=\"unv_40983630\"></span>          <span class=\"navs\">\n             | <a href=\"#40983516\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40984095\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975426\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40983630\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">What difference does it make? It's not like most GenAI provides more value than random tokens.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40983630&amp;goto=item%3Fid%3D40973339%2340983630\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40975426\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975426\" href=\"vote?id=40975426&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=whoami730\" class=\"hnuser\">whoami730</a> <span class=\"age\" title=\"2024-07-16T11:12:07\"><a href=\"item?id=40975426\">1 day ago</a></span> <span id=\"unv_40975426\"></span>          <span class=\"navs\">\n             | <a href=\"#40983516\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974362\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975426\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Is it possible to use this for image recognition and like? Not sure what can be the usage of this apart from as a chatbot.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975426&amp;goto=item%3Fid%3D40973339%2340975426\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980858\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980858\" href=\"vote?id=40980858&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=jononor\" class=\"hnuser\">jononor</a> <span class=\"age\" title=\"2024-07-16T22:20:44\"><a href=\"item?id=40980858\">18 hours ago</a></span> <span id=\"unv_40980858\"></span>          <span class=\"navs\">\n             | <a href=\"#40975426\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40978657\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980858\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Image recognition can generally be done very efficiently on a single commodity PC. Even a phone that is a few years olds can do quite a lot. Or a Raspberry PI. So it generally does not need distributed  computing solutions.\nI am talking about models like YOLO, ResNet, MobileNets, etc.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980858&amp;goto=item%3Fid%3D40973339%2340980858\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40978657\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978657\" href=\"vote?id=40978657&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tama_sala\" class=\"hnuser\">tama_sala</a> <span class=\"age\" title=\"2024-07-16T17:48:30\"><a href=\"item?id=40978657\">23 hours ago</a></span> <span id=\"unv_40978657\"></span>          <span class=\"navs\">\n             | <a href=\"#40975426\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980858\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974362\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978657\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">You can use other models like a vision LLM, or use AI agents as well</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978657&amp;goto=item%3Fid%3D40973339%2340978657\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40974362\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974362\" href=\"vote?id=40974362&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tarasglek\" class=\"hnuser\">tarasglek</a> <span class=\"age\" title=\"2024-07-16T07:39:14\"><a href=\"item?id=40974362\">1 day ago</a></span> <span id=\"unv_40974362\"></span>          <span class=\"navs\">\n             | <a href=\"#40975426\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40974293\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974362\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">This is the first timer i've seen tinygrad backend in the wild. Amusing that it's supposedly more stable than llama.cpp for this project.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974362&amp;goto=item%3Fid%3D40973339%2340974362\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974382\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974382\" href=\"vote?id=40974382&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T07:44:19\"><a href=\"item?id=40974382\">1 day ago</a></span> <span id=\"unv_40974382\"></span>          <span class=\"navs\">\n             | <a href=\"#40974362\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974293\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974382\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Repo author here. Tinygrad changes rapidly so wouldn't it say it's \"more\" stable, but it certainly supports more accelerators than llama.cpp. As George Hotz likes to say, it sits somewhere on the spectrum between llama.cpp and Mojo. No hand-written kernels, optimal kernels are generated and found by beam search.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974382&amp;goto=item%3Fid%3D40973339%2340974382\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40974293\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974293\" href=\"vote?id=40974293&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=thom\" class=\"hnuser\">thom</a> <span class=\"age\" title=\"2024-07-16T07:21:49\"><a href=\"item?id=40974293\">1 day ago</a></span> <span id=\"unv_40974293\"></span>          <span class=\"navs\">\n             | <a href=\"#40974362\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40979398\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974293\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Bexowulf.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974293&amp;goto=item%3Fid%3D40973339%2340974293\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40979398\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979398\" href=\"vote?id=40979398&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=cess11\" class=\"hnuser\">cess11</a> <span class=\"age\" title=\"2024-07-16T19:17:44\"><a href=\"item?id=40979398\">22 hours ago</a></span> <span id=\"unv_40979398\"></span>          <span class=\"navs\">\n             | <a href=\"#40974293\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979398\" n=\"5\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I look forward to something similar being developed on top of Bumblebee and Axon, which I expect is just around the corner. Because, for me, Python does not spark joy.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979398&amp;goto=item%3Fid%3D40973339%2340979398\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40979496\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979496\" href=\"vote?id=40979496&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T19:28:37\"><a href=\"item?id=40979496\">21 hours ago</a></span> <span id=\"unv_40979496\"></span>          <span class=\"navs\">\n             | <a href=\"#40979398\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979496\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Repo author here. This sounds interesting. Could you elaborate on the benefits of Bumblebee / Axon?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979496&amp;goto=item%3Fid%3D40973339%2340979496\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40979801\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979801\" href=\"vote?id=40979801&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=cess11\" class=\"hnuser\">cess11</a> <span class=\"age\" title=\"2024-07-16T20:03:17\"><a href=\"item?id=40979801\">21 hours ago</a></span> <span id=\"unv_40979801\"></span>          <span class=\"navs\">\n             | <a href=\"#40979398\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40979496\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979801\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">They run on the BEAM, and there are related IoT-platforms like Nerves. If find that to be a much nicer runtime than (C)Python.<p>Edit: I don't know where else to begin. It's a runtime that has lightweight processes, excellent observability, absurdly good fault tolerance, really nice programming languages and so on. It's designed for distributed computing.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979801&amp;goto=item%3Fid%3D40973339%2340979801\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40979862\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"3\"><img src=\"s.gif\" height=\"1\" width=\"120\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40979862\" href=\"vote?id=40979862&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T20:10:04\"><a href=\"item?id=40979862\">21 hours ago</a></span> <span id=\"unv_40979862\"></span>          <span class=\"navs\">\n             | <a href=\"#40979398\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40979801\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40979862\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Fascinating, will check this out! I wanted to focus on Python first to build this quickly, test out ideas and iterate.<p>This seems like a good option for a switch.</p><p>Do you know if any of these can run on Apple/Android devices?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40979862&amp;goto=item%3Fid%3D40973339%2340979862\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40983975\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"4\"><img src=\"s.gif\" height=\"1\" width=\"160\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40983975\" href=\"vote?id=40983975&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=cess11\" class=\"hnuser\">cess11</a> <span class=\"age\" title=\"2024-07-17T09:31:04\"><a href=\"item?id=40983975\">7 hours ago</a></span> <span id=\"unv_40983975\"></span>          <span class=\"navs\">\n             | <a href=\"#40979398\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40979862\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40983975\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">I avoid touching Apple devices but anything that can expose a Linux shell can run the BEAM. There are two main projects for small devices, <a href=\"https://nerves-project.org/\" rel=\"nofollow\">https://nerves-project.org/</a> for more ordinary SoC-computers and <a href=\"https://www.atomvm.net/\" rel=\"nofollow\">https://www.atomvm.net/</a> for stuff like ESP32-chips.<p>On Android you've got Termux in F-Droid and can pull in whatever BEAM-setup you want. That's how I first started dabbling with the BEAM, I was using a tablet for most of my recreational programming and happened to try it out and got hooked.</p><p>Erlang is pretty weird, but it just clicks for some people so it's worth spending some time checking it out. Elixir is a really nice Python-/Ruby-like on the BEAM, but with pattern matching, real macros and all the absurdly powerful stuff in the Open Telecom Platform.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40983975&amp;goto=item%3Fid%3D40973339%2340983975\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                                    <tr class=\"athing comtr\" id=\"40981465\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40981465\" href=\"vote?id=40981465&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=Obertr\" class=\"hnuser\">Obertr</a> <span class=\"age\" title=\"2024-07-17T00:12:52\"><a href=\"item?id=40981465\">17 hours ago</a></span> <span id=\"unv_40981465\"></span>          <span class=\"navs\">\n             | <a href=\"#40979398\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40975827\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40981465\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Okey, I'll say it. It will not work because of network bottlneckes. You need to be sending gigabytes of Data.<p>so by definition you need (1) good internet 20mb/s+ and (2) good devices.</p><p>This thing will not go any further than cool demo on twitter. Please prove me wrong.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40981465&amp;goto=item%3Fid%3D40973339%2340981465\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40981532\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40981532\" href=\"vote?id=40981532&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-17T00:25:33\"><a href=\"item?id=40981532\">16 hours ago</a></span> <span id=\"unv_40981532\"></span>          <span class=\"navs\">\n             | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40975827\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40981532\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Try it out - don't trust me!<p>The way this works is that each device holds a partition of the model (for now a continuous set of layers). E.g. let's say you have 3 devices and the model is 32 layers. Device 1 could hold layers 1-10, device 2 holds 11-20 and device 3 holds 21-32. Each device executes the layers it's responsible for and passes on the output of its last layer (the activations) to the next device.</p><p>The activations are ~8KB for Llama-3-8B and ~32KB for Llama-3-70B (it's linear in the number of parameters in that layer and Llama-3-70B has more layers). Generally the larger the model gets (in terms of parameters), the more layers it ends up having, so we end up with sub-linear scaling so I expect Llama-3-405B to have activations on the order of ~100KB.</p><p>This is totally acceptable to send over a local network. The main issue you run into is latency, not bandwidth. Since LLMs are autoregressive (tokens are generated serially), additional latency limits throughput. However, over a local network latency is generally very low (&lt;5ms in my experience). And if not, it's still useful depending on the use-case since you can get a lot of throughput with pipeline parallelism (overlapping requests): <a href=\"https://pytorch.org/docs/stable/pipeline.html\" rel=\"nofollow\">https://pytorch.org/docs/stable/pipeline.html</a></p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40981532&amp;goto=item%3Fid%3D40973339%2340981532\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40975827\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40975827\" href=\"vote?id=40975827&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=christkv\" class=\"hnuser\">christkv</a> <span class=\"age\" title=\"2024-07-16T12:18:39\"><a href=\"item?id=40975827\">1 day ago</a></span> <span id=\"unv_40975827\"></span>          <span class=\"navs\">\n             | <a href=\"#40981465\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40980959\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40975827\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Is apple silicon with a lot of memory 32Gb and up still considered a cheapish way to run models or are there other options now?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40975827&amp;goto=item%3Fid%3D40973339%2340975827\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40977690\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977690\" href=\"vote?id=40977690&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=talldayo\" class=\"hnuser\">talldayo</a> <span class=\"age\" title=\"2024-07-16T15:55:20\"><a href=\"item?id=40977690\">1 day ago</a></span> <span id=\"unv_40977690\"></span>          <span class=\"navs\">\n             | <a href=\"#40975827\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980959\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977690\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">A good Apple Silicon Mac with 32gb of RAM will cost you over $2,000 on-sale. For that price you might as well buy an Nvidia machine instead, either two 3090s or a 64gb Jetson Orin board would be both cheaper and faster.<p>The markup on Apple hardware is so big that I just don't think \"cheapish\" will ever be a way to describe the position they hold in the AI market. Apple's current budget lineup gets smoked by an RTX 3060 in a cheap Linux homeserver; the bar for high-value AI has been raised pretty high.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977690&amp;goto=item%3Fid%3D40973339%2340977690\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40980959\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980959\" href=\"vote?id=40980959&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=pkeasjsjd\" class=\"hnuser\">pkeasjsjd</a> <span class=\"age\" title=\"2024-07-16T22:35:58\"><a href=\"item?id=40980959\">18 hours ago</a></span> <span id=\"unv_40980959\"></span>          <span class=\"navs\">\n             | <a href=\"#40975827\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40978404\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980959\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c5a\">It bothers me that they don't talk about security here, I don't like it at all.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980959&amp;goto=item%3Fid%3D40973339%2340980959\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980969\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980969\" href=\"vote?id=40980969&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T22:37:53\"><a href=\"item?id=40980969\">18 hours ago</a></span> <span id=\"unv_40980969\"></span>          <span class=\"navs\">\n             | <a href=\"#40980959\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40978404\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40980969\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">You’re right. The assumption right now is that you’re running on trusted devices on your own local network. I will add a section in the README.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980969&amp;goto=item%3Fid%3D40973339%2340980969\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40978404\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978404\" href=\"vote?id=40978404&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=throwawaymaths\" class=\"hnuser\">throwawaymaths</a> <span class=\"age\" title=\"2024-07-16T17:19:51\"><a href=\"item?id=40978404\">23 hours ago</a></span> <span id=\"unv_40978404\"></span>          <span class=\"navs\">\n             | <a href=\"#40980959\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978404\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Is this sensible?  Transformers are memory bandwidth bound.  Schlepping activations around your home network (which is liable to be lossy) seems like it would result in atrocious TPS.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978404&amp;goto=item%3Fid%3D40973339%2340978404\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978414\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978414\" href=\"vote?id=40978414&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T17:21:52\"><a href=\"item?id=40978414\">23 hours ago</a></span> <span id=\"unv_40978414\"></span>          <span class=\"navs\">\n             | <a href=\"#40978404\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978414\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">\"Transformers are memory bandwidth bound\" - this is the precise reason why this makes sense. If a model doesn't fit into memory on a single device, it needs to be incrementally loaded into memory (offloading), which is bottlenecked by memory bandwidth. Splitting the model over multiple devices avoids this, instead trading off for latency of communicating between nodes. The network bandwidth requirements are minimal since only the activations (intermediary embeddings) are passed between devices. For Llama-3-8B these are ~10KB, for Llama-3-70B these are ~32KB.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978414&amp;goto=item%3Fid%3D40973339%2340978414\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40985422\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40985422\" href=\"vote?id=40985422&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=boroboro4\" class=\"hnuser\">boroboro4</a> <span class=\"age\" title=\"2024-07-17T13:01:29\"><a href=\"item?id=40985422\">4 hours ago</a></span> <span id=\"unv_40985422\"></span>          <span class=\"navs\">\n             | <a href=\"#40978404\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40978414\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40985422\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">It worth noticing that number you're quoting is for embeddings between layers. If you split your model between 5 nodes you will need to send this 32kb 5 times. Also it's per token. Meaning if you process 1K tokens it turns to be 32 MB of data, 1M tokens - 32 GB...</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40985422&amp;goto=item%3Fid%3D40973339%2340985422\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40977320\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40977320\" href=\"vote?id=40977320&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=ulrischa\" class=\"hnuser\">ulrischa</a> <span class=\"age\" title=\"2024-07-16T15:11:03\"><a href=\"item?id=40977320\">1 day ago</a></span> <span id=\"unv_40977320\"></span>          <span class=\"navs\">\n             | <a href=\"#40978404\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40977320\" n=\"4\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Does somebody know if it runs on a raspberry?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40977320&amp;goto=item%3Fid%3D40973339%2340977320\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978436\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978436\" href=\"vote?id=40978436&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T17:23:42\"><a href=\"item?id=40978436\">23 hours ago</a></span> <span id=\"unv_40978436\"></span>          <span class=\"navs\">\n             | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978436\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">It *should* but I haven't tried it. I will try it. Updated in this issue:<p>We could also try raspberry pi + coral usb tpu (<a href=\"https://coral.ai/products/\" rel=\"nofollow\">https://coral.ai/products/</a>) - that might be a killer combo for super cheap home ai cluster.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978436&amp;goto=item%3Fid%3D40973339%2340978436\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40978439\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40978439\" href=\"vote?id=40978439&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T17:23:58\"><a href=\"item?id=40978439\">23 hours ago</a></span> <span id=\"unv_40978439\"></span>          <span class=\"navs\">\n             | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40978436\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40982689\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40978439\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Issue link: <a href=\"https://github.com/exo-explore/exo/issues/11\">https://github.com/exo-explore/exo/issues/11</a></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40978439&amp;goto=item%3Fid%3D40973339%2340978439\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n            <tr class=\"athing comtr\" id=\"40982689\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40982689\" href=\"vote?id=40982689&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=yjftsjthsd-h\" class=\"hnuser\">yjftsjthsd-h</a> <span class=\"age\" title=\"2024-07-17T04:56:18\"><a href=\"item?id=40982689\">12 hours ago</a></span> <span id=\"unv_40982689\"></span>          <span class=\"navs\">\n             | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40978436\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40978439\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40982689\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">&gt; coral usb tpu<p>I thought those were so memory limited that there was no useful way to run an LLM on them?</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40982689&amp;goto=item%3Fid%3D40973339%2340982689\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40973975\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40973975\" href=\"vote?id=40973975&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=iJohnDoe\" class=\"hnuser\">iJohnDoe</a> <span class=\"age\" title=\"2024-07-16T06:06:24\"><a href=\"item?id=40973975\">1 day ago</a></span> <span id=\"unv_40973975\"></span>          <span class=\"navs\">\n             | <a href=\"#40977320\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40980083\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40973975\" n=\"5\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Anyone run this? Works?</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40973975&amp;goto=item%3Fid%3D40973339%2340973975\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974030\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974030\" href=\"vote?id=40974030&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tdubhro1\" class=\"hnuser\">tdubhro1</a> <span class=\"age\" title=\"2024-07-16T06:23:22\"><a href=\"item?id=40974030\">1 day ago</a></span> <span id=\"unv_40974030\"></span>          <span class=\"navs\">\n             | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974126\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974030\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The readme shows how to run it assuming you can run a python program on the device, so I expect it works with laptops and PCs but there's a note at the end of the page saying that the iOS app has fallen behind the python version so it's not clear to me how to get this running on your iphone or other such devices.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974030&amp;goto=item%3Fid%3D40973339%2340974030\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40974124\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974124\" href=\"vote?id=40974124&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=orsorna\" class=\"hnuser\">orsorna</a> <span class=\"age\" title=\"2024-07-16T06:43:37\"><a href=\"item?id=40974124\">1 day ago</a></span> <span id=\"unv_40974124\"></span>          <span class=\"navs\">\n             | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974030\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974126\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974124\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">The \"device\" in question must be Apple Silicon because the `mlx` package is a hard dependency, or at least an ARM machine (I do not have any Apple Silicon Macbooks or ARM machines to run this). I tried tweaking this before realizing calls to this library is littered all over the repo. I don't really understand the AI ecosystem very well but it seems that the use of the `mlx` library should be supplanted by some other library depending on the platform machine. Until then, and the actual release of the iOS code somewhere, \"everyday devices\" is limited to premium devices that almost no one has more than one of. I'm looking forward to run this on other machine platforms and squeeze out what I can from old hardware laying around. Otherwise I doubt the tagline of the project.<p>Edit: to add on, the only evidence that this runs anywhere but Apple Silicon is the maintainer's Twitter where they show it running on two Macbook Pros as well as other devices. I'm not sure how many of those devices are not ARM.</p><p>I'm not throwing shade at the concept the author is presenting, but I'd appreciate if they could slow down functional commits (he is writing them right now as I type) and truthfully modify the documentation to state which targets are actually able to run this.</p></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974124&amp;goto=item%3Fid%3D40973339%2340974124\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                  <tr class=\"athing comtr\" id=\"40974126\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40974126\" href=\"vote?id=40974126&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=acosmism\" class=\"hnuser\">acosmism</a> <span class=\"age\" title=\"2024-07-16T06:44:23\"><a href=\"item?id=40974126\">1 day ago</a></span> <span id=\"unv_40974126\"></span>          <span class=\"navs\">\n             | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40974030\" class=\"clicky\" aria-hidden=\"true\">prev</a> | <a href=\"#40980083\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40974126\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c5a\">why ask? try it!</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40974126&amp;goto=item%3Fid%3D40973339%2340974126\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40985204\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40985204\" href=\"vote?id=40985204&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=tvshtr\" class=\"hnuser\">tvshtr</a> <span class=\"age\" title=\"2024-07-17T12:38:08\"><a href=\"item?id=40985204\">4 hours ago</a></span> <span id=\"unv_40985204\"></span>          <span class=\"navs\">\n             | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40974126\" class=\"clicky\" aria-hidden=\"true\">parent</a> | <a href=\"#40980083\" class=\"clicky\" aria-hidden=\"true\">next</a> <a class=\"togg clicky\" id=\"40985204\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">sone people value their time</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40985204&amp;goto=item%3Fid%3D40973339%2340985204\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        <tr class=\"athing comtr\" id=\"40980083\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"0\"><img src=\"s.gif\" height=\"1\" width=\"0\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980083\" href=\"vote?id=40980083&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=yjftsjthsd-h\" class=\"hnuser\">yjftsjthsd-h</a> <span class=\"age\" title=\"2024-07-16T20:34:27\"><a href=\"item?id=40980083\">20 hours ago</a></span> <span id=\"unv_40980083\"></span>          <span class=\"navs\">\n             | <a href=\"#40973975\" class=\"clicky\" aria-hidden=\"true\">prev</a> <a class=\"togg clicky\" id=\"40980083\" n=\"3\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Unfortunately I don't see <i>any</i> licensing info, without which I'm not touching it. Which is too bad since the idea is really cool.</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980083&amp;goto=item%3Fid%3D40973339%2340980083\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980349\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"1\"><img src=\"s.gif\" height=\"1\" width=\"40\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980349\" href=\"vote?id=40980349&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=alexandercheema\" class=\"hnuser\">alexandercheema</a> <span class=\"age\" title=\"2024-07-16T21:08:17\"><a href=\"item?id=40980349\">20 hours ago</a></span> <span id=\"unv_40980349\"></span>          <span class=\"navs\">\n             | <a href=\"#40980083\" class=\"clicky\" aria-hidden=\"true\">parent</a> <a class=\"togg clicky\" id=\"40980349\" n=\"2\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Thanks for pointing out that. Fixed <a href=\"https://github.com/exo-explore/exo/blob/main/LICENSE\">https://github.com/exo-explore/exo/blob/main/LICENSE</a></div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980349&amp;goto=item%3Fid%3D40973339%2340980349\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                <tr class=\"athing comtr\" id=\"40980839\"><td><table border=\"0\">  <tbody><tr>    <td class=\"ind\" indent=\"2\"><img src=\"s.gif\" height=\"1\" width=\"80\"></td><td valign=\"top\" class=\"votelinks\">\n      <center><a id=\"up_40980839\" href=\"vote?id=40980839&amp;how=up&amp;goto=item%3Fid%3D40973339\"><div class=\"votearrow\" title=\"upvote\"></div></a></center>    </td><td class=\"default\"><div style=\"margin-top:2px; margin-bottom:-10px;\"><span class=\"comhead\">\n          <a href=\"user?id=yjftsjthsd-h\" class=\"hnuser\">yjftsjthsd-h</a> <span class=\"age\" title=\"2024-07-16T22:17:59\"><a href=\"item?id=40980839\">19 hours ago</a></span> <span id=\"unv_40980839\"></span>          <span class=\"navs\">\n             | <a href=\"#40980083\" class=\"clicky\" aria-hidden=\"true\">root</a> | <a href=\"#40980349\" class=\"clicky\" aria-hidden=\"true\">parent</a> <a class=\"togg clicky\" id=\"40980839\" n=\"1\" href=\"javascript:void(0)\">[–]</a><span class=\"onstory\"></span>          </span>\n                  </span></div><br><div class=\"comment\">\n                  <div class=\"commtext c00\">Excellent, thank you:)</div>\n              <div class=\"reply\">        <p><font size=\"1\">\n                      <u><a href=\"reply?id=40980839&amp;goto=item%3Fid%3D40973339%2340980839\" rel=\"nofollow\">reply</a></u>\n                  </font>\n      </p></div></div></td></tr>\n        </tbody></table></td></tr>\n                        </tbody></table>\n  <br><br>\n</td></tr>\n<tr><td><img src=\"s.gif\" height=\"10\" width=\"0\"><table width=\"100%\" cellspacing=\"0\" cellpadding=\"1\"><tbody><tr><td bgcolor=\"#ff6600\"></td></tr></tbody></table><br>\n<center><span class=\"yclinks\"><a href=\"newsguidelines.html\">Guidelines</a> | <a href=\"newsfaq.html\">FAQ</a> | <a href=\"lists\">Lists</a> | <a href=\"https://github.com/HackerNews/API\">API</a> | <a href=\"security.html\">Security</a> | <a href=\"https://www.ycombinator.com/legal/\">Legal</a> | <a href=\"https://www.ycombinator.com/apply/\">Apply to YC</a> | <a href=\"mailto:hn@ycombinator.com\">Contact</a></span><br><br>\n<form method=\"get\" action=\"//hn.algolia.com/\">Search: <input type=\"text\" name=\"q\" size=\"17\" autocorrect=\"off\" spellcheck=\"false\" autocapitalize=\"off\" autocomplete=\"off\"></form></center></td></tr>      </tbody></table></center>\n      <script type=\"text/javascript\" src=\"hn.js?8yh3lTXcP3rMZEYvdlNS\"></script>\n  \n</body></html>",
	"content": "\tHacker News new | past | comments | ask | show | jobs | submit\tlogin\n\n\n\n\t\n\tExo: Run your own AI cluster at home with everyday devices (github.com/exo-explore)\n\t408 points by simonpure 1 day ago | hide | past | favorite | 141 comments\n\n\t\n\n\n\n\n\n\n\t\n\t\najnin 1 day ago | next [–]\n\n\nIt requires mlx but it is an Apple silicon-only library as far as I can tell. How is it supposed to be (I quote) \"iPhone, iPad, Android, Mac, Linux, pretty much any device\" ? Has it been tested on anything else than the author's MacBook ?\n\nreply\n\n\n\n\t\n\t\nalexandercheema 18 hours ago | parent | next [–]\n\n\nRepo maintainer here. It supports any device tinygrad does, which is a lot. We didn’t expect it to blow up so soon - the repo is still experimental. Internally we’ve mostly been testing on MacBooks and Mac Minis, and that’s where dev is happening. The swift implementation is outdated and currently broken, since Python has been changing so fast (over 20 commits in the last day). On my ToDo is CI/CD pipeline with integration tests for different device and network configurations, so we don’t randomly break stuff for certain devices.\n\nWe’re moving fast to get it stable and usable. The goal is for this to be as simple as running Dropbox. Bear with us :)\n\nreply\n\n\n\n\t\n\t\norsorna 1 day ago | parent | prev | next [–]\n\n\nOne of the maintainers has a video demo on his twitter claiming iOS, android and Linux. Some of the code is not released and I wish they were advertising that properly.\n\nreply\n\n\n\n\t\n\t\ntama_sala 7 hours ago | root | parent | next [–]\n\n\nThe library already has tinygrad support it seems, so it's not limited to Apple & MLX\n\nreply\n\n\n\n\t\n\t\norsorna 1 hour ago | root | parent | next [–]\n\n\nThat is true. However (as of two days ago, it may have rapidly changed since then) the python program did not differentiate based on your architecture and would try to import mlx regardless if it's installable on your system or not, causing import errors.\n\nreply\n\n\n\n\t\n\t\nlopuhin 1 day ago | parent | prev | next [–]\n\n\nThe README says they plan to add llama.cpp support which should cover a lot of targets, also they have tinygrad already integrated I think.\n\nreply\n\n\n\n\t\n\t\ndcreater 1 day ago | prev | next [–]\n\n\nThis is a great ideal and user friendly as well. Has the potential of converting multiple old devices overnight from being useless. However, I wish they had provided some results on tok/s, latency with some example setups.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 1 day ago | parent | next [–]\n\n\nWe didn't expect this to blow up so quickly. A lot of work needs to be done on getting different setups working. I have made an issue here: https://github.com/exo-explore/exo/issues/11\n\nreply\n\n\n\n\t\n\t\nDiogoSnows 19 hours ago | root | parent | next [–]\n\n\nThis is great work! I will keep an eye (and maybe even try to contribute). Looking back at the beginning of Google, I think their use of hardware and hardware agnostic platform likely contributed to support growth at lower cost. We need more of that in the AI era\n\nreply\n\n\n\n\t\n\t\nalexandercheema 18 hours ago | root | parent | next [–]\n\n\nThank you for the support! I agree on the cost point, and personally I don’t want to live in a world where all AI runs on H100s in a giant datacenter controlled by one company.\n\nreply\n\n\n\n\t\n\t\nmg 1 day ago | prev | next [–]\n\n\n\n    This enables you to run larger models\n    than you would be able to on any single\n    device.\n\nNo further explanation on how this is supposed to work?\n\nIf some layers of the neural network are on deviceA and some layers are on deviceB, wouldn't that mean that for every token generated, all output data from the last layer on deviceA have to be transferred to deviceB?\n\nreply\n\n\n\n\t\n\t\nmikewarot 1 day ago | parent | next [–]\n\n\nYes, so you would have a vector about 8k values long to be transferred on each token generated.\n\nYou could do that easily with any modern network.\n\nreply\n\n\n\n\t\n\t\nmg 1 day ago | root | parent | next [–]\n\n\nThat's exciting. So we could build a SETI@home style network of even the largest models.\n\nI wonder if training could be done in this way too.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 1 day ago | root | parent | next [–]\n\n\nRepo author here. That's correct. The embeddings for Llama-3-8B are around 8KB-10KB. For Llama-3-70B they're around 32KB. These are small enough to send around between devices on a local network. For a SETI@home style network, latency will kill you if you go over the internet. That's why we're starting with local networks.\n\nreply\n\n\n\n\t\n\t\njuvo 1 day ago | root | parent | next [–]\n\n\nhow does it compare to https://github.com/bigscience-workshop/petals ?\n\nreply\n\n\n\n\t\n\t\nDiogoSnows 19 hours ago | root | parent | prev | next [–]\n\n\nFor generating synthetic data you could have a SETI@Home setup if you consider each home as a node that generates some amount of data. I mean, such a setup can be built with Exo, I wouldn’t suggest including it as part of Exo.\n\nOut of curiosity, would you ever support training or at least fine-tuning?\n\nreply\n\n\n\n\t\n\t\nmg 1 day ago | root | parent | prev | next [–]\n\n\nAh yes. At first, I thought that since it is all one-way forward-only communication, latency would only affect the time to the first token.\n\nBut I guess the final output needs to be sent back to the first node before it can continue. So if there are 50 nodes with a latency of 40ms each, each token would take 2s to process.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 1 day ago | root | parent | next [–]\n\n\nYeah, unfortunately the autoregressive nature of these models slows it down significantly with added device<->device latency. However, you can still max out on throughput with pipeline parallelism, where you overlap execution. See: https://pytorch.org/docs/stable/pipeline.html\n\nreply\n\n\n\n\t\n\t\nsteeve 1 day ago | parent | prev | next [–]\n\n\nYes, that’s how it works (pipeline parallelism)\n\nreply\n\n\n\n\t\n\t\nmg 1 day ago | root | parent | next [–]\n\n\nInteresting. Let's do the math ...\n\nLet's say the model has 50B parameters and 50 layers. That would mean about one billion values have to travel through the wifi for every generated token?\n\nI wonder how much data that is in bytes and how long it takes to transfer them.\n\nreply\n\n\n\n\t\n\t\nblackbear_ 1 day ago | root | parent | next [–]\n\n\nIt's not the parameters that are sent, it's the layer outputs. That makes for a few thousands floats per token\n\nreply\n\n\n\n\t\n\t\nmg 1 day ago | root | parent | next [–]\n\n\nWoops! I would have thought the number of neurons roughly equals the number of parameters, but you are right. The number of parameters is much higher.\n\nreply\n\n\n\n\t\n\t\ntama_sala 23 hours ago | root | parent | next [–]\n\n\nThe embedding size is only 8k so while the parameters are 70B. So it's a huge difference\n\nreply\n\n\n\n\t\n\t\npyinstallwoes 1 day ago | prev | next [–]\n\n\nSwarm compute should be the norm for all compute - so much unused cpu across all the devices we collectively own.\n\nreply\n\n\n\n\t\n\t\nphito 1 day ago | parent | next [–]\n\n\nI'd rather my CPU to be idle and not consome much power\n\nreply\n\n\n\n\t\n\t\nimp0cat 22 hours ago | root | parent | next [–]\n\n\nIt depends. There is a lot of devices with quite capable cpus that are mostly doing nothing.\n\nreply\n\n\n\n\t\n\t\nbastawhiz 18 hours ago | root | parent | next [–]\n\n\nI also prefer my phone to not be hot and constantly plugged in. Or for my ML workload to suddenly get slow because my partner drove the car out of range of the WiFi. Or to miss notifications because my watch's CPU was saturated.\n\nreply\n\n\n\n\t\n\t\nKronisLV 1 day ago | parent | prev | next [–]\n\n\nThis might not work for use cases where you need low latency, but for longer winded processing it would be amazing if possible.\n\nFor example, if I have a few servers, laptop (connected to power) as well as a desktop PC and they’re all connected to a fast local network, it’d be great to distribute the task of rendering a video or working with archive files across all of them.\n\nreply\n\n\n\n\t\n\t\ngreggsy 1 day ago | root | parent | next [–]\n\n\nThose are two precise examples that benefit from single core compute power, and are wholly unsuited to distributed computing…\n\nreply\n\n\n\n\t\n\t\nKronisLV 1 day ago | root | parent | next [–]\n\n\nDistributed rendering farms have existed for a while.\n\nreply\n\n\n\n\t\n\t\ngreggsy 3 hours ago | root | parent | next [–]\n\n\nThey render a single frame though. Admittedly, so does video rendering.\n\nreply\n\n\n\n\t\n\t\n_factor 1 day ago | parent | prev | next [–]\n\n\nThis exists: https://aihorde.net/\n\nI haven’t tried it, and not the norm, but I agree it should be more common. We have a global supercomputer with higher latency, but still a supercomputer.\n\nreply\n\n\n\n\t\n\t\ndchuk 1 day ago | root | parent | next [–]\n\n\nI might just still be too tired from just waking up, but I can’t for the life of me find any details on that site about what models are actually being served by the horde?\n\nreply\n\n\n\n\t\n\t\nburkaman 1 day ago | root | parent | next [–]\n\n\nGo to https://aihorde.net/api/, scroll down to /v2/status/models, and click Try it out and then Execute. It's an enormous list and I think it can be dynamically updated, so that's probably why it isn't listed on the website.\n\nreply\n\n\n\n\t\n\t\nhagope 1 day ago | prev | next [–]\n\n\nI used to be excited about running models locally (LLM, stable diffusion etc) on my Mac, PC, etc. But now I have resigned to the fact that most useful AI compute will mostly be in the cloud. Sure, I can run some slow Llama3 models on my home network, but why bother when it is so cheap or free to run it on a cloud service? I know Apple is pushing local AI models; however, I have serious reservations about the impact on battery performance.\n\nreply\n\n\n\n\t\n\t\nPostOnce 1 day ago | parent | next [–]\n\n\nMaybe you want to conduct experiments that the cloud API doesn't allow for.\n\nPerhaps you'd like to plug it into a toolchain that runs faster than API calls can be passed over the network? -- eventually your edge hardware is going to be able to infer a lot faster than the 50ms+ per call to the cloud.\n\nMaybe you would like to prevent the monopolists from gaining sole control of what may be the most impactful technology of the century.\n\nOr perhaps you don't want to share your data with Microsoft & Other Evils (formerly known as dont be evil).\n\nYou might just like to work offline. Whole towns go offline, sometimes for days, just because of bad weather. Nevermind war and infrastructure crises.\n\nOr possibly you don't like that The Cloud model has a fervent, unshakeable belief in the propaganda of its masters. Maybe that propaganda will change one day, and not in your favor. Maybe you'd like to avoid that.\n\nThere are many more reasons in the possibility space than my limited imagination allows for.\n\nreply\n\n\n\n\t\n\t\ntarruda 1 day ago | root | parent | next [–]\n\n\nIt is not like strong models are at a point where you can 100% trust their output. It is always necessary to review LLM generated text before using it.\n\nI'd rather have a weaker model which I can always rely on being available than a strong model which is hosted by a third party service that can be shut down at any time.\n\nreply\n\n\n\n\t\n\t\nAurornis 1 day ago | root | parent | next [–]\n\n\n> I'd rather have a weaker model which I can always rely on being available than a strong model which is hosted by a third party service that can be shut down at any time.\n\nEvery LLM project I’ve worked with has an abstraction layer for calling hosted LLMs. It’s trivial to implement another adapter to call a different LLM. It’s often does as a fallback, failover strategy.\n\nThere are also services that will merge different providers into a unified API call if you don’t want to handle the complexity on the client.\n\nIt’s really not a problem.\n\nreply\n\n\n\n\t\n\t\nPostOnce 18 hours ago | root | parent | next [–]\n\n\nSuppose you live outside of America and the supermajority of LLM companies are American. You want to ask a question about whisky distillation or abortion or anything else that's legal in your jurisdiction but not in the US, but the LLM won't answer.\n\nYou've got a plethora of cloud providers, all of them aligned to a foreign country's laws and customs.\n\nIf you can choose between Anthropic, OpenAI, Google, and some others... well, that's really not a choice at all. They're all in California. What good does that do an Austrian or an Australian?\n\nreply\n\n\n\n\t\n\t\nneop1x 8 hours ago | root | parent | prev | next [–]\n\n\nAlso hosted models are often censored and refuse talking about various topics.\n\nreply\n\n\n\n\t\n\t\nsharpshadow 21 hours ago | root | parent | prev | next [–]\n\n\nExcellent points and being able to use available hardware in unison is amazing and I guess we are not far away from botnets utilising this kind of technology like they did with mining coins.\n\nreply\n\n\n\n\t\n\t\ngtirloni 1 day ago | root | parent | prev | next [–]\n\n\n> eventually your edge hardware is going to be able to infer a lot faster than the 50ms+ per call to the cloud.\n\nThis is interesting. Is that based on any upcoming technology improvement already in the works?\n\nreply\n\n\n\n\t\n\t\na_t48 1 day ago | root | parent | next [–]\n\n\nGP is likely referring to network latency here. There's a tradeoff between smaller GPUs/etc at home that have no latency to use and beefier hardware in the cloud that have a minimum latency to use.\n\nreply\n\n\n\n\t\n\t\nyjftsjthsd-h 22 hours ago | root | parent | next [–]\n\n\nSure, but if the model takes multiple seconds to execute, then even 100 milliseconds of network latency seems more or less irrelevant\n\nreply\n\n\n\n\t\n\t\ndatameta 20 hours ago | root | parent | prev | next [–]\n\n\nComms is also the greatest battery drain for a remote edge system. Local inference can allow for longer operation, or operation with no network infra.\n\nreply\n\n\n\n\t\n\t\njumpCastle 1 day ago | root | parent | prev | next [–]\n\n\nAren't services like runpod solve half of these concerns?\n\nreply\n\n\n\n\t\n\t\njacooper 8 hours ago | root | parent | prev | next [–]\n\n\nPersonally I found the biggest problem for local models is the lack of integrationa, it can't search the web, it can't use wolfram alpha for math, etc\n\nLLMs are great as routers, only rarely are they good doing something on their own.\n\nreply\n\n\n\n\t\n\t\nwokwokwok 1 day ago | parent | prev | next [–]\n\n\n> Sure, I can run some slow Llama3 models on my home network, but why bother when it is so cheap or free to run it on a cloud service?\n\nObvious answer: because it's not free, and it's not cheap.\n\nIf you're playing with a UI library, lets say, QT... would you:\n\na) install the community version and play with ($0)\n\nb) buy a professional license to play with (3460 €/Year)\n\nWhich one do you pick?\n\nWell, the same goes. It turns out, renting a server large enough to run big (useful, > 8B) models is actually quite expensive. The per-api-call costs of real models (like GPT4) adds up very quickly once you're doing non-trivial work.\n\nIf you're just messing around with the tech, why would you pay $$$$ just to piss around with it and see what you can do?\n\nWhy would you not use a free version running on your old PC / mac / whatever you have lying around?\n\n> I used to be excited about running models locally\n\nThat's an easy position to be one once you've already done it and figured out, yes, I really want the pro plan to build my $StartUP App.\n\nIf you prefer to pay for an online service and you can afford it, absolutely go for it; but isn't this an enabler for a lot of people to play and explore the tech for $0?\n\nIsn't having more people who understand this stuff and can make meaningful (non-hype) decisions about when and where to use it good?\n\nIsn't it nice that if meta released some 400B llama 4 model, most people can play with it, not just the ones with the $7000 mac studio? ...and keep building the open source ecosystem?\n\nIsn't that great?\n\nI think it's great.\n\nEven if you don't want to play, I do.\n\nreply\n\n\n\n\t\n\t\njrm4 1 day ago | root | parent | next [–]\n\n\nRight, I think people here are vastly underestimating this idea of\n\n\"What if I want to play around with really PERSONAL stuff.\"\n\nI've been keeping a digital journal about my whole life. I plan to throw that thing into an AI to see what happens, and you can be damn sure that it will be local.\n\nreply\n\n\n\n\t\n\t\nmonkmartinez 23 hours ago | root | parent | next [–]\n\n\nYes, I am with you 100% and keep several LLaMA's on my workstation for that reason. I use Openrouter for everything else. Everything that isn't sensitive goes to one of the big kid models because they are just sooooo much better. LLaMA 400b might be the start of running with the big kids, but I know we are not close with the current available models.\n\nreply\n\n\n\n\t\n\t\nitake 1 day ago | root | parent | prev | next [–]\n\n\nI’m a bit confused. Your reasoning doesn’t align with the data you shared.\n\nThe startup costs for just messing around at home are huge: purchasing a server and gpus, paying for electricity, time spent configuring the api.\n\nIf you want to just mess around, $100 to call the world’s best api is much cheaper than spending $2-7k Mac Studio.\n\nEven at production level traffic, the ROI on uptime, devops, utilities, etc would take years to recapture the upfront and on-going costs of self-hosting.\n\nSelf hosting will have higher latency and lower throughput.\n\nreply\n\n\n\n\t\n\t\nzeta0134 1 day ago | root | parent | next [–]\n\n\nYou are vastly overestimating the startup cost. For me this week it was literally these commands:\n\npacman -S ollama\n\nollama serve\n\nollama run llama3\n\nMy basic laptop with about 16 GB of RAM can run the model just fine. It's not fast, but it's reasonably usable for messing around with the tech. That's the \"startup\" cost. Everything else is a matter of pushing scale and performance, and yes that can be expensive, but a novice who doesn't know what they need yet doesn't have to spend tons of money to find out. Almost any PC with a reasonable amount of RAM gets the job done.\n\nreply\n\n\n\n\t\n\t\nmonkmartinez 23 hours ago | root | parent | next [–]\n\n\nllama3 at 8billion params is weak sauce for anything serious, it just isn't in the same galaxy as Sonnet 3.5 or GPT-4o. The smaller and faster models like Phi are even worse. Once you progress past asking trivial questions to a point where you need to trust the output a bit more, its not worth effort in time, money and/or sweat effort to run a local model to do it.\n\nA novice isn't going to know what they need because they don't know what they don't know. Try asking a question to LLaMA 3 at 8 billion and the same question to LLaMA 3 at 70 billion. There is a night and day difference. Sonnet, Opus and GPT-4o run circles around LLaMA 3 70b. To run LLaMA at 70 billion you need serious horse power as well, likely thousands of dollars in hardware investment. I say it again... the calculus in time, money, and effort isn't favorable to running open models on your own hardware once you pass the novice stage.\n\nI am not ungrateful that the LLaMA's are available for many different reasons, but there is no comparison between quality of output, time, money and effort. The API's are a bargain when you really break down what it takes to run a serious model.\n\nreply\n\n\n\n\t\n\t\njononor 19 hours ago | root | parent | next [–]\n\n\nUsing an LLM as a general purpose knowledge base is only one particular application of an LLM. And on which is probably best served by ChatGPT etc.\n\nA lot of other things are possible with LLMs using the context window and completion, thanks to their \"zero shot\" learning capabilities. Which is also what RAG builds upon.\n\nreply\n\n\n\n\t\n\t\nAurornis 1 day ago | root | parent | prev | next [–]\n\n\nI’m familiar with local models. They’re fine for chatting on unimportant things.\n\nThey do not compare to the giant models like Claude Sonnet and GPT4 when it comes to trying to use them for complex things.\n\nI continue to use both local models and the commercial cloud offerings, but I think anyone who suggests that the small local models are on par with the big closed hosted models right now is wishful thinking.\n\nreply\n\n\n\n\t\n\t\nsudohackthenews 1 day ago | root | parent | prev | next [–]\n\n\nPeople have gotten manageable results on all sorts of hardware. People have even squeezed a few tokens/second out of Raspberry PIs. The small models are pretty performant- they get good results on consumer gaming hardware. My 2021 laptop with a 3070m (only 8gb vram) runs 8b models faster than I can read, and even the original M1 chips can run the models fine.\n\nreply\n\n\n\n\t\n\t\nmonkmartinez 22 hours ago | root | parent | next [–]\n\n\nYou are right of course.... IF your metric for manageable/useable is measured only tokens per second (tok/s).\n\nIf your metric is quality of output, time, money and tok/s, there is no comparison; Local models just aren't there yet.\n\nreply\n\n\n\n\t\n\t\nLorenDB 1 day ago | root | parent | prev | next [–]\n\n\nAnd why would you buy a Mac Studio? You could build a reasonable GPU-accelerated Linux box for well under $1500. For example: https://pcpartpicker.com/guide/BCWG3C/excellent-amd-gamingst...\n\nreply\n\n\n\n\t\n\t\nJ_Shelby_J 1 day ago | root | parent | next [–]\n\n\nDevs that refuse to move off Apple are severely disadvantaged in the LLM era.\n\nreply\n\n\n\n\t\n\t\njondwillis 1 day ago | root | parent | next [–]\n\n\nlol tell that to the 3 year old laptop with 64 GB of RAM that I use exclusively for local LLMs while dev’ing on my work laptop with 96 GB of RAM…\n\nreply\n\n\n\n\t\n\t\nwokwokwok 1 day ago | root | parent | prev | next [–]\n\n\n> The startup costs for just messing around at home are huge\n\nNo, they are zero.\n\nMost people have extra hardware lying around at home they're not using. It costs nothing but time to install python.\n\n$100 is not free.\n\nIf you can't be bothered, sure thing, slap down that credit card and spend your $100.\n\n...but, maybe not so for some people?\n\nConsider students with no credit card, etc; there are a lot of people with a lot of free time and not a lot of money. Even if you don't want to use it do you do seriously think this project is totally valueless for everyone?\n\nMaybe, it's not for you. Not everything has to be for everyone.\n\nYou are, maybe, just not the target audience here?\n\nreply\n\n\n\n\t\n\t\nAurornis 1 day ago | root | parent | next [–]\n\n\n> You are, maybe, just not the target audience here?\n\nThe difference between an open model running on a $100 computer and the output from GPT4 or Claude Sonnet is huge.\n\nI use local and cloud models. The difference in productivity and accuracy between what I can run locally and what I can get for under $100 of API calls per month is huge once you get past basic playing around with chat. It’s not even close right now.\n\nSo I think actually you are not the target audience for what the parent comments are taking about. If you don’t need cutting edge performance then it’s fun to play with local, open, small models. If the goal is to actually use LLMs for productivity in one way or another, spending money on the cloud providers is a far better investment.\n\nExceptions of course for anything that is privacy-sensitive, but you’re still sacrificing quality by using local models. It’s not really up for debate that the large hosted models are better than what you’d get from running a 7B open model locally.\n\nreply\n\n\n\n\t\n\t\nlynx23 1 day ago | root | parent | prev | next [–]\n\n\nAnd its not entitled to cliam that \"Most people have extra hardware lying around at home\". Your story doesn't sound plausible at all.\n\nreply\n\n\n\n\t\n\t\nbryanrasmussen 1 day ago | root | parent | next [–]\n\n\nMost people who would want to be running machine learning models probably have some hardware at home that can handle a slow task for playing around and determining if it is worthwhile to pay out for something more performant.\n\nThis is undoubtedly entitled, but thinking to yourself huh, I think it's time to try out some of this machine learning stuff is a pretty inherently entitled thing to do.\n\nreply\n\n\n\n\t\n\t\nwokwokwok 1 day ago | root | parent | prev | next [–]\n\n\nThis project is literally aiming to run on devices like old phones.\n\nI don't think having an old phone is particularly entitled.\n\nI think casually slapping down $100 on whim to play with an API... probably, yeah.\n\n/shrug\n\nreply\n\n\n\n\t\n\t\nitake 1 day ago | root | parent | next [–]\n\n\nAccording to this tweet, Llama 3 costs about $0.20 per Million tokens using an M2.\n\nhttps://x.com/awnihannun/status/1786069640948719956\n\nIn comparison, GPT3.5-turbo costs $0.50 per million tokens.\n\nDo you think an old iPhone will less than 2x efficient?\n\nreply\n\n\n\n\t\n\t\nnightski 1 day ago | root | parent | next [–]\n\n\nFWIW depends on cost of power. Where I live cost of power is less than half the stated average.\n\nreply\n\n\n\n\t\n\t\nnl 1 day ago | root | parent | prev | next [–]\n\n\n> Well, the same goes. It turns out, renting a server large enough to run big (useful, > 8B) models is actually quite expensive. The per-api-call costs of real models (like GPT4) adds up very quickly once you're doing non-trivial work.\n\nI run my own models, but the truth is most of the time I just use an API provider.\n\nTogetherAI and Groq both have free offers that are generous enough I haven't used them up in 6 months of experimentation and TogetherAI in particular has more models and gets new models up quicker than I can try them myself.\n\nreply\n\n\n\n\t\n\t\nFeepingCreature 1 day ago | root | parent | prev | next [–]\n\n\nI just prepay $20/mo to openrouter.ai and can instantly play with every model, no further signup required.\n\nreply\n\n\n\n\t\n\t\nAurornis 1 day ago | root | parent | prev | next [–]\n\n\n> Why would you not use a free version running on your old PC / mac / whatever you have lying around?\n\nBecause the old PC lying around can’t come anywhere near the abilities or performance of the hosted AI compute providers. Orders of magnitudes of difference.\n\nThe parent commenter is correct: If you want cutting edge performance, there’s no replacement for the hosted solutions right now.\n\nRunning models locally is fun for playing around and experimenting, but there is no comparison between what you can run on an old PC lying around and what you can get from a hosted cluster of cutting edge hardware that offers cheap output priced per API call.\n\nreply\n\n\n\n\t\n\t\ndotancohen 1 day ago | parent | prev | next [–]\n\n\nI have found many similarities between home AI and home astronomy. The equipment needed to get really good performance is far beyond that available to the home user, however intellectually satisfying results can be had at home as a hobby. But certainly not professional results.\n\nreply\n\n\n\n\t\n\t\ngrugagag 1 day ago | root | parent | next [–]\n\n\nWhen learning and experimenting it could make a difference.\n\nreply\n\n\n\n\t\n\t\nCantinflas 1 day ago | parent | prev | next [–]\n\n\nWhy bother running models locally? Privacy, for once, or censorship resistance.\n\nreply\n\n\n\n\t\n\t\nseasonman 1 day ago | root | parent | next [–]\n\n\nAlso customizability. Sure, you can fine-tune the cloud hosted models (to a certain degree of freedom), but it will probably be expensive, inefficient, difficult and unmaintainable.\n\nreply\n\n\n\n\t\n\t\nhanniabu 1 day ago | root | parent | prev | next [–]\n\n\nAnd offline access\n\nreply\n\n\n\n\t\n\t\ndsign 1 day ago | parent | prev | next [–]\n\n\nFor my advanced spell-checking use-case[^1], local LLMs are, sadly, not state-of-the-art. But their $0 price-point is excellent to analyze lots of sentences and catch the most obvious issues. With some clever hacking, the most difficult cases can be handled by GPT4o and Claude. I'm glad there is a wide variety of options.\n\n[^1] Hey! If you know of spell-checking-tuned LLM models, I'm all ears (eyes).\n\nreply\n\n\n\n\t\n\t\nbruce343434 1 day ago | root | parent | next [–]\n\n\nI think the floating point encoding of LLMs is inherently lossy, add to that the way tokenization works. The LLMs I've worked with \"ignore\" bad spelling and correctly interpret misspelled words. I'm guessing that for spelling LLMs, you'd want tokenization at the character level, rather than a byte pair encoding.\n\nYou could probably train any recent LLM to be better than a human at spelling correction though, where \"better\" might be a vague combination of faster, cheaper, and acceptable loss of accuracy. Or maybe slightly more accurate.\n\n(A lot of people hate on LLMs for not being perfect, I don't get it. LLMs are just a tool with their own set of trade offs, no need to get rabid either for or against them. Often, things just need to be \"good enough\". Maybe people on this forum have higher standards than average, and can not deal with the frustration of that cognitive dissonance)\n\nreply\n\n\n\n\t\n\t\nHihowarewetoday 1 day ago | parent | prev | next [–]\n\n\nI'm not sure why you have resigned?\n\nIf you don't care about running it locally, just spend it online. Everything is good.\n\nBut you can run it locally already. Is it cheap? No. Are we still in the beginning? yes. We are still in a phase were this is a pure luxury and just getting into it by buying a 4090, is still relativly cheap in my opinion.\n\nWhy running it locally you ask? I personally think running anythingllm and similiar frameworks on your own local data is interesting.\n\nBut im pretty sure in a few years you will be able to buy cheaper ml chips for running models locally fast and cheap.\n\nBtw. aat least i don't know a online service which is uncensored, has a lot of loras as choice and is cost effective. For just playing around with LLMs for sure there are plenty of services.\n\nreply\n\n\n\n\t\n\t\ndiego_sandoval 1 day ago | parent | prev | next [–]\n\n\n> why bother when it is so cheap or free to run it on a cloud service?\n\nFor the same reasons that we bother to use Open Source software instead of proprietary software.\n\nreply\n\n\n\n\t\n\t\njrm4 1 day ago | parent | prev | next [–]\n\n\nWhat do you mean by useful here?\n\nI'm saying because I've had the exact OPPOSITE thought. The intersection of Moore's Law and the likelihood that these things won't end up as some big unified singularity brain and instead little customized use cases make me think that running at home/office will perhaps be just as appealing.\n\nreply\n\n\n\n\t\n\t\nfriendly_chap 1 day ago | parent | prev | next [–]\n\n\nWe are running smaller models with software we wrote (self plug alert: https://github.com/singulatron/singulatron) with great success. There are obvious mistakes these models make (such as the one in our repo image - haha) sometimes but they can also be surprisingly versatile in areas you don't expect them to be, like coding.\n\nOur demo site uses two NVIDIA GeForce RTX 3090 and our whole team is hammering it all day. The only problem is occasionally high GPU temperature.\n\nI don't think the picture is as bleak as you paint. I actually expect Moore's Law and better AI architectures to bring on a self-hosted AI revolution in the next few years.\n\nreply\n\n\n\n\t\n\t\ndws 1 day ago | parent | prev | next [–]\n\n\n> Sure, I can run some slow Llama3 models on my home network, but why bother when it is so cheap or free to run it on a cloud service?\n\nRunning locally, you can change the system prompt. I have Gemma set up on a spare NUC, and changed the system prompt from \"helpful\" to \"snarky\" and \"kind, honest\" to \"brutally honest\". Having an LLM that will roll its eyes at you and say \"whatever\" is refreshing.\n\nreply\n\n\n\n\t\n\t\nnhod 1 day ago | parent | prev | next [–]\n\n\nIs this a hunch, or do you know of some data to back up your reservations?\n\nCopilot+ PC’s, which all run models locally, have the best battery life of any portable PC devices, ever.\n\nThese devices have in turn taken a page out of Apple Silicon’s playbook. Apple has the benefit of deep hardware and software integration that no one else has, and is obsessive about battery life.\n\nIt is reasonable to think that battery life will not be impacted much.\n\nreply\n\n\n\n\t\n\t\nfragmede 1 day ago | root | parent | next [–]\n\n\nThat doesn't seem totally reasonable. The battery life of an iphone is pretty great if you're not actually using it, but if you're using the device hard, it gets hot to the touch, along with the battery getting drained. playing resource intensive video games, maxing out the *PU won't stop and let the device sleep at all, and has a noticable hit on battery life. Where inference takes a lot of compute to perform, it's hard to imagine inference being totally free, battery-wise. It probably won't be as hard on the device as playing specific video games non-stop, but I get into phone conversations with ChatGPT as it is, so I can imagine that being a concern if you're already low on battery.\n\nreply\n\n\n\n\t\n\t\naftbit 1 day ago | parent | prev | next [–]\n\n\nWhat if you want to create transcripts for 100s of hours of private recorded audio? I for one do not want to share that with the cloud providers and have it get used as training data or be subject to warrentless search under the third party doctrine. Or what if you want to run a spicy Stable Diffusion fine-tune that you'd rather not have associated with your name in case the anti-porn fascists take over? I feel like there are dozens of situations where the cost is really not the main reason to prefer a local solution.\n\nreply\n\n\n\n\t\n\t\nbongodongobob 1 day ago | parent | prev | next [–]\n\n\nI have a 2 year old Thinkpad and I wouldn't necessarily call llama3 slow on it. It's not as fast as ChatGPT but certainly serviceable. This should only help.\n\nNot sure why your throwing your hands up because this is a step towards solving your problem.\n\nreply\n\n\n\n\t\n\t\ncess11 22 hours ago | parent | prev | next [–]\n\n\nI don't want people I don't know snooping around in my experiments.\n\nreply\n\n\n\n\t\n\t\nmatyaskzs 1 day ago | prev | next [–]\n\n\nCloud cannot be beaten on compute / price, but moving to local could solve privacy issues and the world needs a second amendment for compute anyway.\n\nreply\n\n\n\n\t\n\t\ndijit 16 hours ago | parent | next [–]\n\n\n> Cloud cannot be beaten on compute / price\n\nSorry, I can't let misinformation like that slide.\n\nCloud cost/benefit ratio is not good in many circumstances.\n\nFor hobbyists it works well because you run your job for very brief periods and renting is much cheaper than buying in those cases. Similarly, if your business usage is so low as to be effectively run once per day then cloud has major benefits.\n\nHowever, if you are doing any kind of work that consumes more than 8hrs of computer time in a day, cloud is going to start being much more expensive.\n\nThe exact cost/benefit depends on the SKU and I'm mostly talking about CPU/Memory/Storage- for managed services like databases it's significantly worse, and I'm comparing to rented servers not self-hosting at home, which is significantly cheaper still.\n\nLocal hardware has downsides (availability, inflexibility), but it's faster and cheaper in almost all real workload scenarios where the compute would otherwise be completely idle/turned off >90% of the time.\n\nreply\n\n\n\n\t\n\t\nCuriouslyC 1 day ago | parent | prev | next [–]\n\n\nYou can beat gpt4/claude in terms of price/performance for most things by a mile using fine tuned models running in a colo. Those extra parameters give the chatbots the ability to understand malformed input and to provide off the cuff answers about almost anything, but small models can be just as smart about limited domains.\n\nreply\n\n\n\n\t\n\t\nComputerGuru 1 day ago | root | parent | next [–]\n\n\nThe problem is that once you say “fine tuned” then you have immediately slashed the user base down to virtually nothing. You need to fine-tune per-task and usually per-user (or org). There is no good way to scale that.\n\nApple can fine-tune a local LLM to respond to a catalog of common interactions and requests but it’s hard to see anyone else deploying fine-tuned models for non-technical audiences or even for their own purposes when most of their needs are one-off and not recurring cases of the same thing.\n\nreply\n\n\n\n\t\n\t\nCuriouslyC 1 day ago | root | parent | next [–]\n\n\nNot necessarily, you can fine tune on a general domain of knowledge (people already do this and open source the results) then use on device RAG to give it specific knowledge in the domain.\n\nreply\n\n\n\n\t\n\t\nfudged71 18 hours ago | prev | next [–]\n\n\nSince this is best over a local network, I wonder how easy you could make the crowdsourcing aspect of this. How could you make it simple enough for everyone that's physically in your office to join a network to train overnight? Or get everyone at a conference to scan a QR code to contribute to a domain specific model.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 18 hours ago | parent | next [–]\n\n\nThat’s where we want to get eventually. There’s a lot of work that needs to be done but I’m confident we’ll get there. Give us 3 months and it’ll be as simple as running Dropbox.\n\nreply\n\n\n\n\t\n\t\nJayakumark 20 hours ago | prev | next [–]\n\n\nJust got https://github.com/distantmagic/paddler working across 2 machines on windows, for load balancing, This will be next level and useful for Llama 400B to run across multiple machines. But looks like windows support is not there yet.\n\nreply\n\n\n\n\t\n\t\ngnicholas 13 hours ago | prev | next [–]\n\n\nThis is great! I really wish Apple allowed your device to query a model you host instead of skipping to their cloud (or OpenAI). I'd love to have a Studio Pro running at home, and have my iPhone, iPad, Mac, and HomePod be able to access it instead of going to the cloud. That way I could have even more assured privacy, and I could choose what model I want to run.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 13 hours ago | parent | next [–]\n\n\nDo you mean with Apple Intelligence? You can already query models you host from Apple using exo or even just local on-device inference.\n\nreply\n\n\n\n\t\n\t\ngnicholas 12 hours ago | root | parent | next [–]\n\n\nDoes this work with Siri? I'm not running the beta so am not familiar with the features and limitations, but I thought that it was either answering based on on-device inference (using a closed model) or Apple's cloud (using a model you can't choose). My understanding is that you can ask OpenAI via an integration they've built, and that in the future you may be able to reach out to other hosted models. But I didn't see anything about being able to seamlessly reach out to your own locally-hosted models, either for Siri backup or anything else. But like I said, I'm not running the beta!\n\nreply\n\n\n\n\t\n\t\nmakmanalp 1 day ago | prev | next [–]\n\n\nQuestion - if large clusters are reporting that they're seeing gains from using RDMA networks because communication overhead is a bottleneck, how is it possible that this thing is not massively bottlenecked running over a home network?\n\nreply\n\n\n\n\t\n\t\nDistractionRect 1 day ago | parent | next [–]\n\n\nI suspect that most of the devices you'd expect to find in your consumer cluster are too small/slow to saturate the link.\n\nEdit: it's also a matter of scale. You probably have a small number of small/slow devices in a consumer network versus a lot of large/fast devices in your enterprise cluster.\n\nreply\n\n\n\n\t\n\t\nderefr 1 day ago | parent | prev | next [–]\n\n\nI haven't looked into exactly what this project is doing, but here's my understanding:\n\nInference across O(N) pre-trained hidden layers isn't exactly an \"embarrassingly parallel\" problem, but it is an \"embarrassingly pipeline-able\" problem (in the CPU sense of \"pipelining.\") Each device can keep just one or a few layers hot in their own VRAM; and also only needs to send and receive one small embedding (<1MB) vector per timestep — which is so trivial that it's easily achievable in realtime even if all the devices are on wi-fi, talking to the same router, in your \"noisy\" apartment where 100 other neighbours are on the same bands.\n\n(To put it another way: running a single inference job, has more forgiving realtime latency+throughput requirements than game streaming!)\n\nAssuming that you have a model that's too big for any of your home machines to individually hold; and that all you care about is performance for single-concurrent-request inference on that model — then in theory, you just need one GPU of one node of your homespun Beowulf GPU cluster to have enough VRAM to keep the single largest layer of your model always-hot; and then other smaller devices can handle keeping the smaller layers always-hot. And the result should be faster than \"overloading\" that same model on that single largest-VRAM device and having some layers spill to CPU, or worse yet, having the GPU have to swap layers in and out repeatedly with each inference step.\n\n(Also, if you're wondering, in the case where a single machine/node has multiple GPUs — or a GPU+VRAM and also a CPU+RAM! — you can treat this as no different than if these were multiple independent nodes, that just-so-happen to have a very efficient pipeline communication channel between them. As the VRAM+computation cost of running inference far outweighs the communication overhead of forward propagation during inference, a home-network inference-pipelining cluster scheduler like this project, would still likely \"schedule\" the model's layers purely in consideration of the properties of the individual GPU+VRAM (or CPU+RAM), rather than bothering to care about placement.)\n\n---\n\nThat being said, AFAIK training is \"pipeline parallelizable\" exactly as inference is. And people training models do do this — but almost always only across multiple top-of-the-line GPUs in one machine; not across multiple machines.\n\nWhen you think about what pipelining achieves for training — all you get is either:\n\n1. the ability to use a bunch of small-aggregate-VRAM nodes to achieve the aggregate training capacity of fewer, larger-aggregate-VRAM nodes — but with more power consumption = higher OpEx; and where also, if you scale this to O(N), then you're dumping a quadratic amount of layer-propagation data (which is now both forward-prop and backprop data, and backprop data is bigger!) over what would likely be a shared network just to make this work. (If it's not a shared network — i.e. if it's Infiniband/other RDMA — then why did you spend all that CapEx for your network and not on your GPUs!?)\n\n2. the ability to pipeline a bunch of large-aggregate-VRAM nodes together to train a model that will then never be able to be deployed onto any single node in existence, but can instead only exist as a \"pipelined inference model\" that hogs O(log N) nodes of your cluster at a time for any inference run. Which makes cluster scheduling hell (if you aren't just permanently wiring the scheduler to treat O(log N)-node groups as single \"hyper-nodes\"); makes it so that you'll never be able to practically open-source the model in a way anybody but other bigcorps could ever run it (if that's something you care about); and very likely means you're cutting the concurrent-inference-request-serving capacity of your huge expensive GPU cluster by O(log N)... which the product team that allowed that cluster to be budgeted is really not gonna like.\n\nThat being said, I imagine at some point one of these proprietary \"Inference-as-a-Service\" models has been trained at a layer size that puts it into pipelined-inference-only territory, temporarily. Doing so would be the ML engineer's equivalent to the CPU engineer's \"we have no fundamentally clever advance, so this quarter we'll just crank up the clock frequency and deal with the higher TDP.\" (Heck, maybe GPT-4o is one of these.)\n\n---\n\nWhat people with GPU clusters want, is 1. for the output of the process to be a model that runs on a single (perhaps multi-GPU) node; and 2. for the process itself to be mostly-shared-nothing with as little cross-node communication burden as possible (such that it's just a question of building highly internally communication-efficient nodes, not so much highly-communication-efficient clusters.)\n\nAnd both of those goals are achieved by sizing models so that they fit within a single node; continuously fanning out streams of training data to those nodes; and then periodically fanning back in model-weights (or model-weight deltas) in an AllReduce operation, to merge the learning of O(N) independently-training nodes to become the new baseline for those nodes.\n\n(If you'll note, this architecture doesn't put any latency requirements on the network, only some monstrous throughput requirements [at the fan-in step] — which makes it a lot easier to design for.)\n\nreply\n\n\n\n\t\n\t\nrbanffy 7 hours ago | prev | next [–]\n\n\nThe all important question:\n\nWhen there’s only one device left on the network, will it sing Daisy Bell?\n\nreply\n\n\n\n\t\n\t\npierrefermat1 1 day ago | prev | next [–]\n\n\nWould be great if we could get some benchmarks on commonly available hardware setups.\n\nreply\n\n\n\n\t\n\t\nfestive-minsky 20 hours ago | parent | next [–]\n\n\nSo I just tried with 2x macbook pros (M2 64GB & M3 128GB) and it was exactly the same speed as with just 1 macbook pro (M2 64GB) Not exactly a common setup but at least it's something\n\nreply\n\n\n\n\t\n\t\nalexandercheema 19 hours ago | root | parent | next [–]\n\n\nCould you create a GitHub issue? There's a lot of work we'd like to do to improve this.\n\nreply\n\n\n\n\t\n\t\npharrington 1 day ago | parent | prev | next [–]\n\n\nI'm sure someone will show their benchmarks in a couple years!\n\nreply\n\n\n\n\t\n\t\nthrowaway2562 9 hours ago | prev | next [–]\n\n\nHow long before the accursed crypto kids try to tokenise token generation with Exo clusters?\n\nreply\n\n\n\n\t\n\t\nrbanffy 7 hours ago | parent | next [–]\n\n\nCrypto kids driving development of general purpose hardware is a win-win scenario\n\nreply\n\n\n\n\t\n\t\nrjzzleep 8 hours ago | parent | prev | next [–]\n\n\nWhat difference does it make? It's not like most GenAI provides more value than random tokens.\n\nreply\n\n\n\n\t\n\t\nwhoami730 1 day ago | prev | next [–]\n\n\nIs it possible to use this for image recognition and like? Not sure what can be the usage of this apart from as a chatbot.\n\nreply\n\n\n\n\t\n\t\njononor 18 hours ago | parent | next [–]\n\n\nImage recognition can generally be done very efficiently on a single commodity PC. Even a phone that is a few years olds can do quite a lot. Or a Raspberry PI. So it generally does not need distributed computing solutions. I am talking about models like YOLO, ResNet, MobileNets, etc.\n\nreply\n\n\n\n\t\n\t\ntama_sala 23 hours ago | parent | prev | next [–]\n\n\nYou can use other models like a vision LLM, or use AI agents as well\n\nreply\n\n\n\n\t\n\t\ntarasglek 1 day ago | prev | next [–]\n\n\nThis is the first timer i've seen tinygrad backend in the wild. Amusing that it's supposedly more stable than llama.cpp for this project.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 1 day ago | parent | next [–]\n\n\nRepo author here. Tinygrad changes rapidly so wouldn't it say it's \"more\" stable, but it certainly supports more accelerators than llama.cpp. As George Hotz likes to say, it sits somewhere on the spectrum between llama.cpp and Mojo. No hand-written kernels, optimal kernels are generated and found by beam search.\n\nreply\n\n\n\n\t\n\t\nthom 1 day ago | prev | next [–]\n\n\nBexowulf.\n\nreply\n\n\n\n\t\n\t\ncess11 22 hours ago | prev | next [–]\n\n\nI look forward to something similar being developed on top of Bumblebee and Axon, which I expect is just around the corner. Because, for me, Python does not spark joy.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 21 hours ago | parent | next [–]\n\n\nRepo author here. This sounds interesting. Could you elaborate on the benefits of Bumblebee / Axon?\n\nreply\n\n\n\n\t\n\t\ncess11 21 hours ago | root | parent | next [–]\n\n\nThey run on the BEAM, and there are related IoT-platforms like Nerves. If find that to be a much nicer runtime than (C)Python.\n\nEdit: I don't know where else to begin. It's a runtime that has lightweight processes, excellent observability, absurdly good fault tolerance, really nice programming languages and so on. It's designed for distributed computing.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 21 hours ago | root | parent | next [–]\n\n\nFascinating, will check this out! I wanted to focus on Python first to build this quickly, test out ideas and iterate.\n\nThis seems like a good option for a switch.\n\nDo you know if any of these can run on Apple/Android devices?\n\nreply\n\n\n\n\t\n\t\ncess11 7 hours ago | root | parent | next [–]\n\n\nI avoid touching Apple devices but anything that can expose a Linux shell can run the BEAM. There are two main projects for small devices, https://nerves-project.org/ for more ordinary SoC-computers and https://www.atomvm.net/ for stuff like ESP32-chips.\n\nOn Android you've got Termux in F-Droid and can pull in whatever BEAM-setup you want. That's how I first started dabbling with the BEAM, I was using a tablet for most of my recreational programming and happened to try it out and got hooked.\n\nErlang is pretty weird, but it just clicks for some people so it's worth spending some time checking it out. Elixir is a really nice Python-/Ruby-like on the BEAM, but with pattern matching, real macros and all the absurdly powerful stuff in the Open Telecom Platform.\n\nreply\n\n\n\n\t\n\t\nObertr 17 hours ago | prev | next [–]\n\n\nOkey, I'll say it. It will not work because of network bottlneckes. You need to be sending gigabytes of Data.\n\nso by definition you need (1) good internet 20mb/s+ and (2) good devices.\n\nThis thing will not go any further than cool demo on twitter. Please prove me wrong.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 16 hours ago | parent | next [–]\n\n\nTry it out - don't trust me!\n\nThe way this works is that each device holds a partition of the model (for now a continuous set of layers). E.g. let's say you have 3 devices and the model is 32 layers. Device 1 could hold layers 1-10, device 2 holds 11-20 and device 3 holds 21-32. Each device executes the layers it's responsible for and passes on the output of its last layer (the activations) to the next device.\n\nThe activations are ~8KB for Llama-3-8B and ~32KB for Llama-3-70B (it's linear in the number of parameters in that layer and Llama-3-70B has more layers). Generally the larger the model gets (in terms of parameters), the more layers it ends up having, so we end up with sub-linear scaling so I expect Llama-3-405B to have activations on the order of ~100KB.\n\nThis is totally acceptable to send over a local network. The main issue you run into is latency, not bandwidth. Since LLMs are autoregressive (tokens are generated serially), additional latency limits throughput. However, over a local network latency is generally very low (<5ms in my experience). And if not, it's still useful depending on the use-case since you can get a lot of throughput with pipeline parallelism (overlapping requests): https://pytorch.org/docs/stable/pipeline.html\n\nreply\n\n\n\n\t\n\t\nchristkv 1 day ago | prev | next [–]\n\n\nIs apple silicon with a lot of memory 32Gb and up still considered a cheapish way to run models or are there other options now?\n\nreply\n\n\n\n\t\n\t\ntalldayo 1 day ago | parent | next [–]\n\n\nA good Apple Silicon Mac with 32gb of RAM will cost you over $2,000 on-sale. For that price you might as well buy an Nvidia machine instead, either two 3090s or a 64gb Jetson Orin board would be both cheaper and faster.\n\nThe markup on Apple hardware is so big that I just don't think \"cheapish\" will ever be a way to describe the position they hold in the AI market. Apple's current budget lineup gets smoked by an RTX 3060 in a cheap Linux homeserver; the bar for high-value AI has been raised pretty high.\n\nreply\n\n\n\n\t\n\t\npkeasjsjd 18 hours ago | prev | next [–]\n\n\nIt bothers me that they don't talk about security here, I don't like it at all.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 18 hours ago | parent | next [–]\n\n\nYou’re right. The assumption right now is that you’re running on trusted devices on your own local network. I will add a section in the README.\n\nreply\n\n\n\n\t\n\t\nthrowawaymaths 23 hours ago | prev | next [–]\n\n\nIs this sensible? Transformers are memory bandwidth bound. Schlepping activations around your home network (which is liable to be lossy) seems like it would result in atrocious TPS.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 23 hours ago | parent | next [–]\n\n\n\"Transformers are memory bandwidth bound\" - this is the precise reason why this makes sense. If a model doesn't fit into memory on a single device, it needs to be incrementally loaded into memory (offloading), which is bottlenecked by memory bandwidth. Splitting the model over multiple devices avoids this, instead trading off for latency of communicating between nodes. The network bandwidth requirements are minimal since only the activations (intermediary embeddings) are passed between devices. For Llama-3-8B these are ~10KB, for Llama-3-70B these are ~32KB.\n\nreply\n\n\n\n\t\n\t\nboroboro4 4 hours ago | root | parent | next [–]\n\n\nIt worth noticing that number you're quoting is for embeddings between layers. If you split your model between 5 nodes you will need to send this 32kb 5 times. Also it's per token. Meaning if you process 1K tokens it turns to be 32 MB of data, 1M tokens - 32 GB...\n\nreply\n\n\n\n\t\n\t\nulrischa 1 day ago | prev | next [–]\n\n\nDoes somebody know if it runs on a raspberry?\n\nreply\n\n\n\n\t\n\t\nalexandercheema 23 hours ago | parent | next [–]\n\n\nIt *should* but I haven't tried it. I will try it. Updated in this issue:\n\nWe could also try raspberry pi + coral usb tpu (https://coral.ai/products/) - that might be a killer combo for super cheap home ai cluster.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 23 hours ago | root | parent | next [–]\n\n\nIssue link: https://github.com/exo-explore/exo/issues/11\n\nreply\n\n\n\n\t\n\t\nyjftsjthsd-h 12 hours ago | root | parent | prev | next [–]\n\n\n> coral usb tpu\n\nI thought those were so memory limited that there was no useful way to run an LLM on them?\n\nreply\n\n\n\n\t\n\t\niJohnDoe 1 day ago | prev | next [–]\n\n\nAnyone run this? Works?\n\nreply\n\n\n\n\t\n\t\ntdubhro1 1 day ago | parent | next [–]\n\n\nThe readme shows how to run it assuming you can run a python program on the device, so I expect it works with laptops and PCs but there's a note at the end of the page saying that the iOS app has fallen behind the python version so it's not clear to me how to get this running on your iphone or other such devices.\n\nreply\n\n\n\n\t\n\t\norsorna 1 day ago | root | parent | next [–]\n\n\nThe \"device\" in question must be Apple Silicon because the `mlx` package is a hard dependency, or at least an ARM machine (I do not have any Apple Silicon Macbooks or ARM machines to run this). I tried tweaking this before realizing calls to this library is littered all over the repo. I don't really understand the AI ecosystem very well but it seems that the use of the `mlx` library should be supplanted by some other library depending on the platform machine. Until then, and the actual release of the iOS code somewhere, \"everyday devices\" is limited to premium devices that almost no one has more than one of. I'm looking forward to run this on other machine platforms and squeeze out what I can from old hardware laying around. Otherwise I doubt the tagline of the project.\n\nEdit: to add on, the only evidence that this runs anywhere but Apple Silicon is the maintainer's Twitter where they show it running on two Macbook Pros as well as other devices. I'm not sure how many of those devices are not ARM.\n\nI'm not throwing shade at the concept the author is presenting, but I'd appreciate if they could slow down functional commits (he is writing them right now as I type) and truthfully modify the documentation to state which targets are actually able to run this.\n\nreply\n\n\n\n\t\n\t\nacosmism 1 day ago | parent | prev | next [–]\n\n\nwhy ask? try it!\n\nreply\n\n\n\n\t\n\t\ntvshtr 4 hours ago | root | parent | next [–]\n\n\nsone people value their time\n\nreply\n\n\n\n\t\n\t\nyjftsjthsd-h 20 hours ago | prev [–]\n\n\nUnfortunately I don't see any licensing info, without which I'm not touching it. Which is too bad since the idea is really cool.\n\nreply\n\n\n\n\t\n\t\nalexandercheema 20 hours ago | parent [–]\n\n\nThanks for pointing out that. Fixed https://github.com/exo-explore/exo/blob/main/LICENSE\n\nreply\n\n\n\n\t\n\t\nyjftsjthsd-h 19 hours ago | root | parent [–]\n\n\nExcellent, thank you:)\n\nreply\n\n\n\n\n\n\n\nGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact\n\n\nSearch: ",
	"cover_url": "https://pub-73a62c9ac6aa4e91ad159b48b360cc20.r2.dev/screenshots/SseyrJ_3itY0fGeTtUtE4.jpg",
	"title": "Exo: Run your own AI cluster at home with everyday devices | Hacker News",
	"created_at": "2024-07-17T17:20:11.990Z"
}